{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a75b9ab",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Data Analysis\n",
    "In this chapter, we have introduced the concepts of Convolutional Neural Networks (CNN), which are a powerful class of deep learning models particularly suited for image data. And in this project, we apply CNN techniques to a novel task in the domain of urban economics: **analyzing the housing price index of 70 large and medium-sized cities in China**. \n",
    "\n",
    "Rather than using traditional econometric approaches, we adopt a **time series imaging** framework. Specifically, we convert each city’s monthly housing price index time series into an image representation using methods such as Gramian Angular Fields (GAF), Markov Transition Fields (MTF), and Recurrence Plots (RP).\n",
    "\n",
    "These image representations are then used as inputs to a ResNet-18 convolutional neural network. The goal of our model is to predict whether housing prices will increase in the future, framing this as a binary classification problem. This approach demonstrates how modern deep learning techniques can be adapted to structured economic time series data through the lens of image-based learning\n",
    "\n",
    "**Learning Goal**: after finishing this project, you would know:\n",
    "* structure of ResNet18\n",
    "* build ResNet18 in PyTorch\n",
    "\n",
    "## Contents\n",
    "* [0 - Import Packages](#0---import-packages)\n",
    "* [1 - Data](#1---data)\n",
    "  * [1.1 - descriptive analysis](#11---descriptive-analysis)\n",
    "  * [1.2 - imagine time series](#12---imagine-time-series-在后面添加几个chunk画图)\n",
    "  * [1.3 - transform to DataLoader](#13---transform-to-dataloader)\n",
    "* [2 - ResNet](#2---resnet)\n",
    "  * [2.1 - structure](#21---structure)\n",
    "  * [2.2 - basic block](#22---basic-block)\n",
    "  * [2.3 - build ResNet18](#23---build-resnet18)\n",
    "* [3 - Train and Test Utility](#3---train-and-test-utility)\n",
    "* [4 - Results](#4---results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ac2bb",
   "metadata": {},
   "source": [
    "## 0 - Import Packages\n",
    "\n",
    "Most packages we have used in previous chapters. In addition, we use 3 algorithms in `pyts` to transform time series into images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627eb126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "# used for time series imaging \n",
    "from pyts.image import GramianAngularField, MarkovTransitionField, RecurrencePlot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3b9ad5",
   "metadata": {},
   "source": [
    "## 1 - Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d50f2fa",
   "metadata": {},
   "source": [
    "Our data includes\n",
    "* $X$: housing price indices for 70 large and medium-sized cities in China from January 2011 to October 2024 ($N = 70, T = 166$)\n",
    "* $y$: if housing price increased between November 2024 and April 2025, then $y = 1$; otherwise, $y = 0$.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80c3011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv') # read data\n",
    "df.head(5) # display first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bed882f",
   "metadata": {},
   "source": [
    "### 1.1 - descriptive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b1cfd9",
   "metadata": {},
   "source": [
    "Firstly, we can visualing the price trends and compare the the average housing price index trends between two classes of cities ($y = 1$ and $y = 0$).\n",
    "\n",
    "We observe \n",
    "* from 2015 to 2018, $y=1$ cities exhibited a faster acceleration in housing prices than $y=0$ cities.\n",
    "* from 2021 to 2023, $y=1$ cities experienced some fluctuation but generally maintained high price levels, while $y=0$ cities underwent a clear and sustained decline\n",
    "\n",
    "This supports the idea that recent housing price performance is path-dependent, and it justifies using time series imaging and deep learning methods to extract rich temporal features for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cf60be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract time series columns\n",
    "ts_columns = [col for col in df.columns if col >= '2011-01' and col <= '2024-10']\n",
    "\n",
    "# transform the time series columns to datetime format\n",
    "months = pd.to_datetime(ts_columns, format='%Y-%m')\n",
    "\n",
    "# calculate mean for each class (y = 1, y = 0)\n",
    "y1_mean = df[df['y'] == 1][ts_columns].mean(axis=0).values\n",
    "y0_mean = df[df['y'] == 0][ts_columns].mean(axis=0).values\n",
    "\n",
    "# calculate standard deviation for each class\n",
    "y1_std = df[df['y'] == 1][ts_columns].std(axis=0).values\n",
    "y0_std = df[df['y'] == 0][ts_columns].std(axis=0).values\n",
    "\n",
    "# plot the average trend for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(months, y1_mean, label=f'y=1 Cities (n={len(df[df[\"y\"]==1])})', color='#E74C3C', linewidth=2.5)\n",
    "plt.plot(months, y0_mean, label=f'y=0 Cities (n={len(df[df[\"y\"]==0])})', color='#3498DB', linewidth=2.5)\n",
    "\n",
    "# plot 0.5*sd for each class\n",
    "plt.fill_between(months, y1_mean - 0.5*y1_std, y1_mean + 0.5*y1_std, color='#F1948A', alpha=0.3)\n",
    "plt.fill_between(months, y0_mean - 0.5*y0_std, y0_mean + 0.5*y0_std, color='#85C1E9', alpha=0.3)\n",
    "\n",
    "# set plot aesthetics\n",
    "plt.title('Average Housing Price Trends by Target Class (y=1 vs y=0)', fontsize=14)\n",
    "plt.xlabel('Year-Month', fontsize=10)\n",
    "plt.ylabel('Average Price Index', fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa2c271",
   "metadata": {},
   "source": [
    "### 1.2 - imagine time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c32d1c9",
   "metadata": {},
   "source": [
    "Next, we need to transform our time series data into images. \n",
    "\n",
    "But before that we define a function `split_housing_price_data` in the following steps:\n",
    "1. extract time series data $X$ in `df` to a NumPy array\n",
    "2. extract label $y$ in `df` to a NumPy array\n",
    "3. extract city names in `df` to a NumPy array\n",
    "4. split into training and testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809fa77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_housing_price_data(df):\n",
    "    '''\n",
    "    split data to train and test array\n",
    "    param:\n",
    "        df: dataframe with columns ['city', 'y', '2011-01', ..., '2024-10'];\n",
    "    return:\n",
    "        train_ts: ndarray with shape [N, T], time series data for training;\n",
    "        test_ts: ndarray with shape [N, T], time series data for testing;\n",
    "        train_y: ndarray with shape [N,], label for training;\n",
    "        test_y: ndarray with shape [N,], label for testing;\n",
    "    '''\n",
    "    # extract time series data to a NumPy array: shape = [N, T]\n",
    "    ts_columns = [col for col in df.columns if '2011-01' <= col <= '2024-10']\n",
    "    X = df[ts_columns].values\n",
    "    \n",
    "    # extract label to a NumPy array: shape = [N,]\n",
    "    y = df['y'].values\n",
    "    \n",
    "    # extract city names to a NumPy array: shape = [N,]\n",
    "    city = df['city'].values\n",
    "    \n",
    "    # split data into training and testing sets\n",
    "    train_ts, test_ts, train_y, test_y, train_city, test_city = train_test_split(X, y, city, test_size=0.2,random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "    return train_ts, test_ts, train_y, test_y, train_city, test_city\n",
    "\n",
    "# split the data into training and testing sets\n",
    "train_ts, test_ts, train_y, test_y, train_city, test_city = split_housing_price_data(df)\n",
    "# display the shapes of the resulting arrays\n",
    "train_ts.shape, test_ts.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b35fd9",
   "metadata": {},
   "source": [
    "Then, we transform our time series into images using 3 algorithms: Gramian Angular Fields, Markov Transition Field and Recurrence Plot. Each converts a 1-dimensional time series into a gray-scale image. We then stack the three gray-scale images along the channel dimension to form a 3-channel image (similar in structure to an RGB image). This 3-channel representation is well-suited as input to a convolutional neural network\n",
    "\n",
    "For the technical details of these 3 algorithms, you can refer to [Wang and Oates (2015)](https://www.ijcai.org/Proceedings/15/Papers/553.pdf). But here for simplicity, you can think of these algorithms as simply visulizing patterns (trends, cycles, anomalies) of time series.\n",
    "\n",
    "To finish above task, we define a function `image_time_series` in the following steps:\n",
    "1. create GAF images\n",
    "2. create MTF images\n",
    "3. create RP images\n",
    "4. stack the images along the channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1fe503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_time_series(ts):\n",
    "    '''\n",
    "    Convert time series data into images\n",
    "    param:\n",
    "        ts: ndarray with shape [N, T], time series;\n",
    "    return:\n",
    "        images: ndarray with shape [N, 3, T, T], 3 channels image of time series;\n",
    "    '''\n",
    "    # create GAF images \n",
    "    gaf = GramianAngularField()\n",
    "    gaf_image = gaf.fit_transform(ts) # shape [N, T, T]\n",
    "\n",
    "    # create MTF images\n",
    "    mtf = MarkovTransitionField(strategy='uniform')\n",
    "    mtf_image = mtf.fit_transform(ts) # shape [N, T, T]\n",
    "\n",
    "    # create RP images\n",
    "    rp = RecurrencePlot(threshold='point')\n",
    "    rp_image = rp.fit_transform(ts) # shape [N, T, T]\n",
    "\n",
    "    # stack the images along the channel dimension\n",
    "    images = np.stack([gaf_image, mtf_image, rp_image], axis=1) #  shape [N, 3, T, T]\n",
    "    \n",
    "    return images\n",
    "\n",
    "train_X = image_time_series(train_ts)\n",
    "test_X = image_time_series(test_ts)\n",
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1490b186",
   "metadata": {},
   "source": [
    "In the following codes, we take Xiamen as an example to show what we have after transforming our time series into images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e36a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find index of '厦门' \n",
    "idx = np.where(train_city == '厦门')[0][0]\n",
    "\n",
    "# extract Xiamen's time series and images\n",
    "ts = train_ts[idx]                   # shape: [T]\n",
    "images = train_X[idx]               # shape: [3, T, T]\n",
    "\n",
    "# create plot with 4 subplots\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "# draw curve of time series\n",
    "axes[0].plot(ts, months, color='black')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Index')\n",
    "axes[0].set_ylabel('Time')\n",
    "\n",
    "# draw GAF image\n",
    "axes[1].imshow(images[0], cmap='gray')\n",
    "axes[1].set_title('GAF')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# draw MTF image\n",
    "axes[2].imshow(images[1], cmap='gray')\n",
    "axes[2].set_title('MTF')\n",
    "axes[2].axis('off')\n",
    "\n",
    "# draw RP image\n",
    "axes[3].imshow(images[2], cmap='gray')\n",
    "axes[3].set_title('RP')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4192a475",
   "metadata": {},
   "source": [
    "### 1.3 - transform to DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d3f61a",
   "metadata": {},
   "source": [
    "Finally, we define a function `prepare_loader`, which transform our Numpy array data into DataLoader, in the following steps:\n",
    "1. transform `X` and `y` into torch.tensor\n",
    "2. bundle `X` and `y` into TensorDataset\n",
    "3. transform TensorDataset into DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea641d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to DataLoader\n",
    "def prepare_loader(X, y, batch_size=64, shuffle=True):\n",
    "    '''\n",
    "    Prepare DataLoader for training and testing\n",
    "    param:\n",
    "        X: ndarray with shape [N, C, T, T], images;\n",
    "        y: ndarray with shape [N,], labels;\n",
    "        batch_size: int, size of each batch;\n",
    "    return:\n",
    "        loader: DataLoader object;\n",
    "    '''\n",
    "    # transform X into torch.tensor\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "    # transform y into torch.tensor\n",
    "    y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    # bundle X_tensor and y_tensor into a TensorDataset\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    \n",
    "    # transform the dataset into a DataLoader\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return loader\n",
    "\n",
    "train_loader = prepare_loader(train_X, train_y, shuffle=True)\n",
    "test_loader = prepare_loader(test_X, test_y, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd428a",
   "metadata": {},
   "source": [
    "## 2 - ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec369c3d",
   "metadata": {},
   "source": [
    "### 2.1 - structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470ff5b",
   "metadata": {},
   "source": [
    "### 2.2 - basic block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52986ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    # 定义扩展因子，用于调整输出通道数\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        \"\"\"\n",
    "        初始化 BasicBlock 模块。\n",
    "\n",
    "        参数:\n",
    "        - in_channels: 输入特征图的通道数\n",
    "        - out_channels: 输出特征图的通道数\n",
    "        - stride: 卷积步长，默认为 1\n",
    "        \"\"\"\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        # 第一个卷积层：3x3 卷积，用于提取特征\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        # 第一个批归一化层：对卷积后的输出进行归一化\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # 第二个卷积层：3x3 卷积，用于进一步提取特征\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        # 第二个批归一化层：对卷积后的输出进行归一化\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # 定义 shortcut 连接（残差连接）\n",
    "        self.shortcut = nn.Sequential()  # 默认 shortcut 是恒等映射（identity mapping）\n",
    "\n",
    "        # 如果步长不为 1 或输入通道数与输出通道数不匹配，则需要调整 shortcut\n",
    "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                # 1x1 卷积，用于调整通道数和空间尺寸\n",
    "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                # 批归一化层\n",
    "                nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 第一层卷积 + 批归一化 + ReLU 激活\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        # 第二层卷积 + 批归一化\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        # 将 shortcut 的输出与主路径的输出相加（残差连接）\n",
    "        out += self.shortcut(x)\n",
    "\n",
    "        # 对相加后的结果应用 ReLU 激活\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d603ff72",
   "metadata": {},
   "source": [
    "### 2.3 - build resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a1c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=2):\n",
    "        \"\"\"\n",
    "        初始化 ResNet 模型。\n",
    "\n",
    "        参数:\n",
    "        - block: 残差块类型（如 BasicBlock）\n",
    "        - num_blocks: 每个阶段的残差块数量（如 [2, 2, 2, 2] 对应 ResNet-18）\n",
    "        - num_classes: 分类任务的类别数\n",
    "        \"\"\"\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        # 初始通道数\n",
    "        self.in_channels = 64\n",
    "\n",
    "        # 初始卷积层：3x3 卷积，用于提取初步特征\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # 构建 4 个阶段的残差块堆叠\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)  # 第一阶段\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)  # 第二阶段\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)  # 第三阶段\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)  # 第四阶段\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # 全局平均池化层\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        \"\"\"\n",
    "        构建一个阶段的残差块堆叠。\n",
    "\n",
    "        参数:\n",
    "        - block: 残差块类型（如 BasicBlock）\n",
    "        - out_channels: 输出通道数\n",
    "        - num_blocks: 残差块数量\n",
    "        - stride: 第一个残差块的步长\n",
    "\n",
    "        返回:\n",
    "        - nn.Sequential: 一个阶段的残差块堆叠\n",
    "        \"\"\"\n",
    "        # 定义每个残差块的步长列表\n",
    "        # 第一个残差块使用指定的 stride，后续残差块使用 stride=1\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "\n",
    "        # 构建每个残差块\n",
    "        for stride in strides:\n",
    "            # 添加一个残差块\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            # 更新输入通道数\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        # 将残差块堆叠成一个序列\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播函数。\n",
    "\n",
    "        参数:\n",
    "        - x: 输入图像\n",
    "\n",
    "        返回:\n",
    "        - out: 分类结果\n",
    "        \"\"\"\n",
    "        # 初始卷积层 + 批归一化 + ReLU 激活\n",
    "        out = self.relu(self.bn1(self.conv1(x))) # (56, 64, 83, 83)\n",
    "        out = self.maxpool(out) # (56, 64, 42, 42)\n",
    "\n",
    "        # 通过 4 个阶段的残差块堆叠\n",
    "        out = self.layer1(out)  # (56, 64, 42, 42)\n",
    "        out = self.layer2(out)  # (56, 128, 21, 21)\n",
    "        out = self.layer3(out)  # (56, 256, 11, 11)\n",
    "        out = self.layer4(out)  # (56, 512, 6, 6)\n",
    "\n",
    "        # 全局平均池化：将特征图的空间维度压缩为 1x1\n",
    "        out = self.avgpool(out) # (56, 512, 1, 1)\n",
    "\n",
    "        # 展平为向量\n",
    "        out = torch.flatten(out, 1) # (56, 512)\n",
    "\n",
    "        # 全连接层：将特征向量映射到类别数量\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d334ca",
   "metadata": {},
   "source": [
    "## 3 - Train and Test Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7539991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs, device):\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_list.append([])\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item()}')\n",
    "                loss_list[-1].append(loss.item())\n",
    "    return loss_list\n",
    "\n",
    "# 测试函数\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            all_probs.append(probs.cpu())\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    return all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c00ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化 ResNet-18 模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNet18()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# 学习率调度器\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d515f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = train(model, train_loader, criterion, optimizer, 100, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7908551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, test_loader, criterion, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405304c8",
   "metadata": {},
   "source": [
    "## 4 - Results and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1c9c50",
   "metadata": {},
   "source": [
    "### 4.1 - ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a23a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e667a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a505ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
