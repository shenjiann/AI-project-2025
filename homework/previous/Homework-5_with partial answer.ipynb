{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homewok 5: LeNet5--Forward Propagation\n",
    "\n",
    "Welcome to the course **AI and Deep learning**! In this homework, we are going to consider the forward propagation for the landmark CNN, LeNet5. The task for this neural network is to identify the handwritten digits from a 32x32 gray-scale images. The details about this architecture are shown below. \n",
    "\n",
    "\n",
    "**Learning Goal**: In this homework, we mainly implement convolution, pooling and fully connected layers.  After this homework, you will know:\n",
    " * How to code up a convolution layer, a pooling layer and a fully connected layer.\n",
    " * You will have a deeper understanding about commands, including np.sum and np.max.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content\n",
    "* [1 - Packages](#1)\n",
    "* [2 - Forward Propagation for LeNet5](#2)\n",
    "  * [2.1 - Generate a training dataset](#2.1)\n",
    "  * [2.2 - Activation functions](#2.2)\n",
    "  * [2.3 - Building blocks](#2.3)\n",
    "  * [2.4 - Integration](#2.4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1- Packages\n",
    "\n",
    "In order to finish a task, we need commands from certain **Python** packages. We need a package **torchvision** to download the handwritten dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T01:56:28.976426Z",
     "start_time": "2024-12-08T01:56:13.520968Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "import numpy as np\n",
    "# import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt # for plots"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next command is used to download the handwritten dataset, including a training dataset and a test dataset. Both datasets contains images and the associated labels. In this homework, we do not touch test dataset, but it is provided for the sake of completion. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T01:56:32.466429Z",
     "start_time": "2024-12-08T01:56:32.204807Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transforms.ToTensor())\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transforms.ToTensor())"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, we only use commands from **numpy** to code up the forward propagation. Thus, we need to obtain np.arrays. Due to the limitation of memory, we may only consider the first 1000 images and labels. The size for the downloaded data is 28x28, but we need 32x32 for analysis. There are several ways to rescale a 28x28 images to 32x32, and we consider padding for simplicity in this homework."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T01:56:37.091732Z",
     "start_time": "2024-12-08T01:56:36.915643Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "train_image = np.pad(np.array(trainset.data),((0,0),(2,2),(2,2)),'constant')[0:1000] # Originally, it is 28 X 28. We need to pad two 0's on all sides to get a 32 X 32 image\n",
    "train_label =np.array(trainset.targets)[0:1000]\n",
    "\n",
    "# The following two lines convert the numeric labels to one-hot representatoin\n",
    "temp = np.eye(10)  \n",
    "train_label_one_hot = temp[train_label,]"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustration purpose, consider the 11th image and its labels. First, we check the numeric label with its one-hot representation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T01:56:39.699266Z",
     "start_time": "2024-12-08T01:56:39.691162Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "i=10\n",
    "print(train_label[i])\n",
    "print(train_label_one_hot[i])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether the image size is 32x32"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T01:56:46.874994Z",
     "start_time": "2024-12-08T01:56:46.857991Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "train_image[i].shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the 11th image as well as its label."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T01:56:50.503169Z",
     "start_time": "2024-12-08T01:56:49.536797Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "plt.imshow(train_image[i], cmap='gray')\n",
    "train_label[i]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Forward Propagation for LeNet5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.1'></a>\n",
    "### 2.1 - Model structure of LeNet5\n",
    "\n",
    "As we have discussed in class, there are five layers with model parameters for LeNet5. The inpute is a 32x32 gray-scale image, and the output is a 10-dimensional probability, since we are dealing with a classification problem with 10 potential classes. The following figure shows the basic structure of LeNet5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet5 consists of the following layers:\n",
    "  * Convolution layer, including 6 kernels, each of size 5x5. Padding is 0 and stride is 1.\n",
    "  * Pooling layer with padding 2 and stride 2.\n",
    "  * Convolution layer, including 16 kernels, each of 5x5x6. Padding is 0 and stride is 1.\n",
    "  * Pooling layer with padding 2 and stride 2.\n",
    "  * Convolution layer, including 120 kernels, each of 5x5x16. Padding is 0 and stride is 1.\n",
    "  * Fully connected layer, including 84 neurons. \n",
    "  * Fully connected layer, including 10 neurons. \n",
    "  \n",
    " The activation function for each hidden layer is tanh, and it is **softmax** for the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.2'></a>\n",
    "### 2.2 - Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the following activation functions:\n",
    "  * sigmoid activation function, $\\sigma(z)=(1+\\exp(-z))^{-1}$ with $\\sigma'(z)=\\sigma(z)\\{1-\\sigma(z)\\}$,\n",
    "  * tanh activation function, $\\sigma(z)=2(1+\\exp(-2z))^{-1}-1$ with $\\sigma'(z)=1-\\sigma^2(z)$,\n",
    "  * softmax activation function."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T02:06:06.907882Z",
     "start_time": "2024-12-08T02:06:06.901132Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "def sigmoid(z):\n",
    "    # x: input\n",
    "    \n",
    "    sig = 1/(1 + np.exp(-z))\n",
    "    \n",
    "    return sig"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T02:06:08.272126Z",
     "start_time": "2024-12-08T02:06:08.262613Z"
    }
   },
   "source": [
    "# PLEASE FINISH THE BLANK PART WITH OTHERS UNCHANGED\n",
    "def tanh(z):\n",
    "    # x: input\n",
    "    \n",
    "    ### YOUR CODE BEGINS HERE (approximately 1 line)\n",
    "    sig = 2/(1 + np.exp(-2*z))-1 # Check the formula and details in the sigmoid function.\n",
    "    ### YOUR CODE ENDS\n",
    "\n",
    "    return sig"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Different from the above two activation function, the following one takes a two-dimensional matrix $Z$ as an input. It first take exponenntial of each element in $Z$, and normalize each row of the resulting matrix."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T02:07:54.547646Z",
     "start_time": "2024-12-08T02:07:54.534674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def softmax(Z):\n",
    "    # We first use exponential function for each element in Z, and normlize each row. \n",
    "    # Z: of size n x d, where n is the sample size and d is the number of feauture.\n",
    "    \n",
    "    ### YOUR CODE BEGINS HERE (approximately 1 line)\n",
    "    A = np.exp(Z)\n",
    "    sum_A = np.sum(A,axis= 1, keepdims=True)\n",
    "    A /= sum_A\n",
    "    ### YOUR CODE ENDS\n",
    "\n",
    "    \n",
    "    return A"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.3'></a>\n",
    "### 2.3 - Building blocks\n",
    "\n",
    "The following code is useful to briefly understand the `dictionary` structure. **The following commands are EXTREMELY important, although it is not so complex.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T02:07:58.539741Z",
     "start_time": "2024-12-08T02:07:58.533903Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "dic = {'W[0]': 0 , 'W[1]':1} # Construct a dictionary"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T02:07:59.852807Z",
     "start_time": "2024-12-08T02:07:59.838687Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "i=0\n",
    "dic['W['+str(i)+']'] #use variables to extract the values for `W[0]`"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need the following one in this homework"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T02:08:01.667771Z",
     "start_time": "2024-12-08T02:08:01.659898Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "dic={} # declare an empty dictionary\n",
    "dic['W']=0 # add a new key and value pair to the dictionary\n",
    "dic['W'] # print the value for the key 'W'"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to initilize the two dictionaries. We implement the following strategies for initialization. \n",
    "   * Initialize the weights by a random vector, whose elements are independently generated from a normal distribution with mean zero and standard deviation one, then divided by the square root of number of elements. Please use a random seed to keep the code reproducible.\n",
    "   * Initialize the bias by zero.\n",
    "\n",
    "\n",
    "The following command may be useful:\n",
    "  * `np.random.normal`: check the help for details.\n",
    "  * `np.zeros`: check the help for details.\n",
    "\n",
    "For example, if we would like to initialize kernels for the first hidden layer, it would be `np.random.normal(0,1,5*5*6).reshape((5,5,6))/sqrt(5*5*6)`, where the first two coordinates are the kernel size and the last one is the number of kernels in this layer. Notice that there are several ways to initialize the kernels and weights randomly, but we just use standard normal distribution scaled by the square root of number of parameters.\n",
    "\n",
    "**Important note**\n",
    "  * Since the input size is 1000x5x5, the dimension of kernel for the first layer is 5x5x6. \n",
    "  * Since the input size is 1000x28x28x6 for the second layer, the kernel for this layer should be 5x5x6x16.\n",
    "  * Always initialize the bias term for convolution layers to be three dimensional. That is, 1x1x6 for the first hidden layer, for example."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T02:08:05.181022Z",
     "start_time": "2024-12-08T02:08:05.163674Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE EXISTING CODE\n",
    "def Initialize_pars(rn):\n",
    "    # rn: random seed\n",
    "    \n",
    "    np.random.seed(rn)\n",
    "    W = {}\n",
    "    b = {}\n",
    "    W[\"[1]\"] = np.random.normal(0,1,5*5*6).reshape((5,5,6))/np.sqrt(5*5*6)\n",
    "    b[\"[1]\"] = np.zeros(6).reshape((1,1,6))\n",
    "    \n",
    "    ### YOUR CODE BEGINS HERE (approximately 8 lines)\n",
    "    W[\"[2]\"] = np.random.normal(0,1,5*5*6*16).reshape((5,5,6,16))/np.sqrt(5*5*6*16) # Check the example for W[\"[1]\"] and b[\"[1]\"]\n",
    "    b[\"[2]\"] = np.zeros(16).reshape((1,1,16))\n",
    "    W[\"[3]\"] = np.random.normal(0,1,5*5*16*120).reshape((5,5,16,120))/np.sqrt(5*5*16*120)\n",
    "    b[\"[3]\"] = np.zeros(120).reshape((1,1,120))\n",
    "    W[\"[4]\"] = np.random.normal(0,1,(84,120))/np.sqrt(84*120)\n",
    "    b[\"[4]\"] = np.zeros((84,1))\n",
    "    W[\"[5]\"] = np.random.normal(0,1,(10,84))/np.sqrt(10*84)\n",
    "    b[\"[5]\"] = np.zeros((10,1))\n",
    "    ### YOUR CODE ENDS\n",
    "    \n",
    "    par = {\n",
    "        'W': W,\n",
    "        'b': b\n",
    "          }\n",
    "    \n",
    "    return par\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T02:08:08.628625Z",
     "start_time": "2024-12-08T02:08:08.612575Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "rn = 1234\n",
    "par = Initialize_pars(rn)\n",
    "print(par['W']['[2]'][0][0][0][0:3])\n",
    "print('Your result should be:\\n[ 0.01012748  0.01626042 -0.00967591]')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01012748  0.01626042 -0.00967591]\n",
      "Your result should be:\n",
      "[ 0.01012748  0.01626042 -0.00967591]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the input size and kernel size, we need to calculate the output size. For example, if the input size is $(n,d_h,d_w,d_c)$ and there are $d_{c,new}$ kernels with size $f\\times f$, then the output size is $(n,d_{h,new},d_{w,new},d_{c,new})$, where $d_{h,new} = \\lfloor (d_h+2p-f)/s\\rfloor+1$, where $p$ and $s$ are padding and stride numbers. The following function is used to obtain the output image size given the input image and kernels. To finish the following code, you may need the following command:\n",
    "  * `//`: try `1//2` and `5//2` by yourself"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T02:08:11.860093Z",
     "start_time": "2024-12-08T02:08:11.847554Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE EXISTING CODE\n",
    "def conv_output_image_size(input_image_size, dc_new, f, p, s):\n",
    "    # input_image_size: the tuple associated with the input image size, and it may of the form (n, dh, dw) or (n, dh, dw, dc), where \n",
    "    #                   n is the sample size, (dh, dw) is the size of each channel, and dc is the number of channels.\n",
    "    # dc_new: number of kernels in this convolution layer\n",
    "    # f: kernel size\n",
    "    # p: padding\n",
    "    # s: stride\n",
    "    \n",
    "    if len(input_image_size) == 3:\n",
    "        n, dh, dw = input_image_size\n",
    "    else:\n",
    "        n, dh, dw,_ = input_image_size\n",
    "        \n",
    "    ### YOUR CODE BEGINS HERE (approximately 2 lines)\n",
    "    dh_new = (dh +2 * p-f)//s + 1  # Check our slide\n",
    "    dw_new = (dw + 2 * p-f)//s + 1 # Check our slide\n",
    "    ### YOUR CODE ENDS\n",
    "    \n",
    "    return (n, dh_new, dw_new, dc_new)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T02:08:14.707906Z",
     "start_time": "2024-12-08T02:08:14.701025Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "input_image_size = (100,28,28,6)\n",
    "dc_new = 16\n",
    "f = 5\n",
    "p=0\n",
    "s=1\n",
    "output_size = conv_output_image_size(input_image_size, 16, 5, 0, 1)\n",
    "print(output_size)\n",
    "print('Your result should be:\\n(100, 24, 24, 16)')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 24, 24, 16)\n",
      "Your result should be:\n",
      "(100, 24, 24, 16)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we code up the convolution layer, and it is one of the important building blocks for CNN. We have demonstrated the details for this layer in class; check the slides for details. The following commands are useful:\n",
    "  * `np.pad`: This is used for padding. If the dimension of X is (n,dh,dw,dc), then try to use `np.pad(X,((0,0),(p,p),(p,p),(0,0)),'constant')` to pad only the matrix in **EACH CHANNEL**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T02:08:17.036808Z",
     "start_time": "2024-12-08T02:08:17.014621Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE EXISTING CODE\n",
    "def conv_layer(input_image, kernel,b,p=0,s=1):\n",
    "    # input_image: np array of the size (n, dh, dw, dc), where n is the sample size, dh, dw and dc are the three dimensions of input images.\n",
    "    #              If the size is (n,dh,dw), then dc=1.\n",
    "    # kernel: np array of the form (k_dh, k_dw, k_dc, k_dc_new), where (k_dh, k_dw, k_dc) is the kernel size, and k_dc_new is the number of kernels.\n",
    "    # p: padding\n",
    "    # s: stride\n",
    "    \n",
    "    ### YOUR CODE BEGINS HERE (approximately 25 lines)\n",
    "    if len(input_image.shape) == 3: # Since our input is gray-scale, there is only one channel for each image. Thus, we omit that channel\n",
    "        input_image = np.pad(input_image,((0,0),(p,p),(p,p)),'constant') # pad the input image\n",
    "    else:\n",
    "        input_image = np.pad(input_image,((0,0),(p,p),(p,p),(0,0)),'constant') # padding the input image. Different from above, we have 4 channels here\n",
    "    \n",
    "    input_image_size = input_image.shape # Obtain the input size\n",
    "    kernel_size = kernel.shape # Obtain the kernel size\n",
    "    \n",
    "    output_size = conv_output_image_size(input_image_size, kernel_size[len(kernel_size)-1], kernel_size[0],p=p,s=s) # Use function conv_output_image_size to get the output image size\n",
    "    output_image = np.zeros(output_size) # Initialize the output image by a tensor with elements beging zero.\n",
    "    \n",
    "    # Loop for each element in the output image\n",
    "    for h_index in range(output_size[1]): # height index\n",
    "        for w_index in range(output_size[2]): # width index\n",
    "            # We need to get the starting and ending index associated with the (h_index, w_index) elements in different channels of the output image\n",
    "            h_range_start = h_index*s # starting height index \n",
    "            h_range_end = h_index*s+kernel_size[0]  # ending height index\n",
    "            w_range_start = w_index*s  # starting width index\n",
    "            w_range_end = w_index*s+kernel_size[0]  # ending width index\n",
    "            \n",
    "            input_image_hwc = input_image[:,h_range_start:h_range_end,w_range_start:w_range_end] # Associated part of the input image to get the (h_index, w_index) elements in different channels of the output image\n",
    "            for c_index in range(output_size[3]): # kernel index. Notice that there are output_size[3] kernels in this layer\n",
    "                if len(input_image_size) == 3: # Since the input size may be three or four dimensional tensor, we consider them individually.\n",
    "                    kernel_c = kernel[:,:,c_index].reshape(1,kernel_size[0],kernel_size[1]) # Extract the c_indexth kernel\n",
    "                    output_image[:,h_index,w_index,c_index] = np.sum(input_image_hwc * kernel_c,axis=(1,2)) + b[0,0,c_index] # Obtain the (h_index, w_index,c_index) elements of the output image for each training example \n",
    "                else: # Same operation but for four dimensional tensors\n",
    "                    kernel_c = kernel[:,:,:,c_index].reshape(1,kernel_size[0],kernel_size[1],input_image_size[3])\n",
    "                    output_image[:,h_index,w_index,c_index] = np.sum(input_image_hwc * kernel_c,axis=(1,2,3))+ b[0,0,c_index]\n",
    "\n",
    "    output_image = tanh(output_image)  # Use tanh as the activation function.\n",
    "    ### YOUR CODE ENDS\n",
    "\n",
    "    return output_image\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-12-08T02:08:21.257639Z",
     "start_time": "2024-12-08T02:08:21.242179Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "np.random.seed(123)\n",
    "input_image = np.random.normal(0,1,200).reshape(2,5,5,4)\n",
    "kernel = np.random.normal(0,1,3*3*4*5).reshape(3,3,4,5)/np.sqrt(3*3*4*5)\n",
    "b = np.random.normal(0,1,5).reshape(1,1,5)\n",
    "p = 0\n",
    "s = 1\n",
    "output_image = conv_layer(input_image, kernel,b,p=0,s=1)\n",
    "print(output_image[0,1,1,1])\n",
    "print('Your result should be:\\n-0.9771451425762684')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9771451425762684\n",
      "Your result should be:\n",
      "-0.9771451425762684\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we consider a pooling layer. Remember that there are no model parameters involved in this layer, and pooling is conducted for each channel. In other words, number of channels does not change after a pooling layer. The following code is useful for max pooling:\n",
    "  * `np.max`. If the dimension of X is (n,dh,dw,dc), then try to use `np.max(X,axis=(1,2))` to compute the maximum number for **EACH CHANNEL**.\n",
    "  * `np.zeros_like(A)`: Generate a tensor of elements being zero, and the result has the same dimension as A."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T02:08:26.323006Z",
     "start_time": "2024-12-08T02:08:26.305239Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE EXISTING CODE\n",
    "def pooling(input_image, p=0, f=2, s=2, tag = \"average\"):\n",
    "    # input_image: np array of the size (n, dh, dw, dc), where n is the sample size, dh, dw and dc are the three dimensions of input images.\n",
    "    # kernel: np array of the form (k_dh, k_dw, k_dc, k_dc_new), where (k_dh, k_dw, k_dc) is the kernel size, and k_dc_new is the number of kernels.\n",
    "    # p: padding\n",
    "    # f: kernel size \n",
    "    # s: stride\n",
    "    # tag: whether \"average\" or \"max\" corresponding to \"average pooling\" or \"max pooling\"\n",
    "    \n",
    "    ### YOUR CODE BEGINS HERE (approximately 20 lines)\n",
    "    input_image_size = input_image.shape  # Obtain the size of the input image\n",
    "    output_size = conv_output_image_size(input_image_size, input_image_size[3], f=2, p=p,s=s)  # Use function conv_output_image_size to obtain the output image size\n",
    "    output_image = np.zeros(output_size)  # Initialize the output image by a tensor with elements beging zero.\n",
    "     \n",
    "    ## Notice that we also need a mask matrix for pooling layer, and the mask matrix is of the same dimension as the input image\n",
    "    if tag.lower() == \"max\":\n",
    "        mask_mat = np.zeros_like(input_image) # use np.zeros_like to generate a tensor of the same size as input image\n",
    "    else:\n",
    "        mask_mat = np.zeros_like(input_image)+1/f/s  # Generate a tensor of the same size as input image, but its elements are 1/f/s\n",
    "    \n",
    "    for h_index in range(output_size[1]):\n",
    "        for w_index in range(output_size[2]):\n",
    "            # We need to get the starting and ending index associated with the (h_index, w_index) elements in different channels of the output image\n",
    "            h_range_start = h_index*s\n",
    "            h_range_end = h_index*s+f\n",
    "            w_range_start = w_index*s\n",
    "            w_range_end = w_index*s+f\n",
    "            input_image_hwc = input_image[:,h_range_start:h_range_end,w_range_start:w_range_end,:]\n",
    "            \n",
    "            # We can use the `axis` argument in np.mean or np.max to avoid a \"for loop\"  associated with the number of channels\n",
    "            if tag.lower() == \"average\":\n",
    "                output_image[:,h_index,w_index,:] = np.mean(input_image_hwc, axis = (1,2)) \n",
    "            else:\n",
    "                hw_max = np.max(input_image_hwc, axis = (1,2),keepdims=True)\n",
    "                mask_mat[:,h_range_start:h_range_end,w_range_start:w_range_end,:] = input_image[:,h_range_start:h_range_end,w_range_start:w_range_end,:] == hw_max\n",
    "                output_image[:,h_index,w_index,:] = hw_max.reshape(input_image_size[0],input_image_size[3])\n",
    "    ### YOUR CODE ENDS\n",
    "        \n",
    "    return(output_image, mask_mat)\n",
    "            "
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T02:08:29.128662Z",
     "start_time": "2024-12-08T02:08:29.115272Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "np.random.seed(123)\n",
    "input_image = np.random.normal(0,1,160).reshape(2,4,4,5)\n",
    "p = 0\n",
    "f = 2\n",
    "s = 2\n",
    "print(\"*\"*8+'  Average pooling')\n",
    "output_image, mask_mat = pooling(input_image, 0,2,2,\"average\")\n",
    "print(output_image[0,1,1,1])\n",
    "print('Your result should be:\\n-0.34565071031429234')\n",
    "output_image, mask_mat = pooling(input_image, 0,2,2,\"max\")\n",
    "print('*'*8+'  Max pooling')\n",
    "print(output_image[0,1,1,1])\n",
    "print('Your result should be:\\n0.8907063912931708')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********  Average pooling\n",
      "-0.34565071031429234\n",
      "Your result should be:\n",
      "-0.34565071031429234\n",
      "********  Max pooling\n",
      "0.8907063912931708\n",
      "Your result should be:\n",
      "0.8907063912931708\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we consider a fully connected layer, and we should be familar with this layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T02:08:39.460141Z",
     "start_time": "2024-12-08T02:08:39.452805Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE EXISTING CODE\n",
    "def fc_layer(input_image, W,b, activation):\n",
    "    # input_image: two dimensional of the form (n,num_feature), where num_feature is the number of features of the input\n",
    "    # W: kernel of size (num_feature_new, num_feature), where num_feature_new is the number of features for the output.\n",
    "    # b: bias tern of size (num_feature_new,1)\n",
    "    # activation: activation\n",
    "\n",
    "    ### YOUR CODE BEGINS HERE (approximately 20 lines)    \n",
    "    output_image = activation(input_image @ W.transpose()+b.transpose())\n",
    "    ### YOUR CODE ENDS\n",
    "\n",
    "    return output_image"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-12-08T02:08:51.225671Z",
     "start_time": "2024-12-08T02:08:51.209893Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "input_image = np.random.normal(0,1,300).reshape(30,10)\n",
    "W = np.random.normal(0,1,8*10).reshape(8,10)/np.sqrt(8*10)\n",
    "b = np.random.normal(0,1,8).reshape(8,1)\n",
    "output_image = fc_layer(input_image, W,b,tanh)\n",
    "print(output_image[0,1])\n",
    "print('Your result should be:\\n-0.860663185653378')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.860663185653378\n",
      "Your result should be:\n",
      "-0.860663185653378\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.4'></a>\n",
    "### 2.4 - Integration \n",
    "\n",
    "Finally, we code up a LeNet5 integrating those functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T02:09:02.513393Z",
     "start_time": "2024-12-08T02:09:02.499035Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE EXISTING CODE\n",
    "def forward(X, one_hot,par):\n",
    "    # X: input image of size (n, dw, dh)\n",
    "    # one_hot: one_hot representation of the labels. \n",
    "    # par: initial parameters\n",
    "\n",
    "    n = X.shape[0] \n",
    "    W = par['W']\n",
    "    b = par['b']\n",
    "\n",
    "    ### YOUR CODE BEGINS HERE (approximately 13 lines) \n",
    "    A1 = conv_layer(input_image = X, kernel = W[\"[1]\"], b = b[\"[1]\"],p=0,s=1) # Results after convolution layer\n",
    "    A1_p, M1 = pooling(A1, p=0, f=2, s=2) # Results after pooling layer\n",
    "    A2 = conv_layer(input_image = A1_p, kernel = W[\"[2]\"], b = b[\"[2]\"],p=0,s=1) # Results after convolution layer\n",
    "    A2_p, M2 = pooling(A2, p=0, f=2, s=2)# Results after pooling layer\n",
    "    A3 = conv_layer(input_image = A2_p, kernel = W[\"[3]\"], b = b[\"[3]\"],p=0,s=1) # Results after convolution layer\n",
    "    A3_vec = A3.reshape(n,120) # Change the four dimensional tensor to a two dimensional matrix\n",
    "    A4 = fc_layer(A3_vec, W[\"[4]\"], b[\"[4]\"], tanh) # Results after fully connected layer layer\n",
    "    A5 = fc_layer(A4, W[\"[5]\"], b[\"[5]\"], softmax) # Results after fully connected layer layer\n",
    "    \n",
    "    J = - np.sum(one_hot * np.log(A5))/n   # Cost function\n",
    "    ### YOUR CODE ENDS\n",
    "    \n",
    "    cache = {\n",
    "        'J': J,\n",
    "        'A1': A1,\n",
    "        'A1_p': A1_p,\n",
    "        'M1': M1,\n",
    "        'A2': A2,\n",
    "        'A2_p': A2_p,\n",
    "        'M2':M2,\n",
    "        'A3':A3,\n",
    "        'A3_vec': A3_vec,\n",
    "        'A4':A4,\n",
    "        'A5':A5\n",
    "    }\n",
    "    return cache\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T02:09:28.036535Z",
     "start_time": "2024-12-08T02:09:23.206768Z"
    }
   },
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "X = train_image\n",
    "one_hot = train_label_one_hot\n",
    "rn = 1234\n",
    "par = Initialize_pars(rn)\n",
    "cache = forward(X, one_hot,par)\n",
    "print(cache['J'])\n",
    "print('Your result should be:\\n2.302640196814468')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.302640196814468\n",
      "Your result should be:\n",
      "2.302640196814468\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced topics:\n",
    "  * How about the backpropagation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
