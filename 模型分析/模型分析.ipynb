{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3834e474",
   "metadata": {},
   "source": [
    "# Model Analysis\n",
    "\n",
    "In the previous chapter, we introduced the basic use of `PyTorch` and use a neural network model to predict the probabilities of listed firms' tax non-compliance behaviors. Our previous model may be too simple, this leads to a bad prediction performance. By tunning the hyperparameters or regularizaition, we can further improve our model.\n",
    "\n",
    "So in section 1- 4, we would introduce the implementation of $\\ell_2$ regularization, dropout, early stopping and batch normalization. These techniques could help avoid over-fitting models. \n",
    "\n",
    "And in section 5, we tune hyperparameters and apply these methods to the example of tax non-compliant firms classfication. \n",
    "\n",
    "**Learning Goal**:\n",
    "1. Implementing regularization methods including L2 penalty, dropout, early stopping;\n",
    "2. Implementing batch normalization;\n",
    "3. Tunning hyperparameters.\n",
    "\n",
    "## Contents\n",
    "* [0 - Import Packages and Data](#0)\n",
    "* [1 - $\\ell_2$ Regularization](#1)\n",
    "* [2 - Dropout](#2)\n",
    "* [3 - Early Stopping](#3)\n",
    "* [4 - Batch Normalization](#4)\n",
    "* [5 - Tunning](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ac1f17",
   "metadata": {},
   "source": [
    "## 0 - Import Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8bca88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x136216e10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd # used for data import\n",
    "import numpy as np # used for numerical operations\n",
    "import torch # used for tensor operations\n",
    "import torch.nn as nn # used for building neural networks\n",
    "from torch.utils.data import DataLoader, TensorDataset # used for creating data loaders\n",
    "from sklearn.preprocessing import StandardScaler # used for standardizing features\n",
    "from sklearn.metrics import average_precision_score # used for evaluating models\n",
    "import matplotlib.pyplot as plt # used for plotting PR curves\n",
    "from sklearn.model_selection import train_test_split # used for splitting data into train/valiadtion sets\n",
    "from utils import FNN, train, test # copy and paste FNN, train, test functions in last chapter to utils.py in your current working directory\n",
    "import itertools # used for generating combinations of hyperparameters\n",
    "import json # used for write output to txt\n",
    "\n",
    "np.random.seed(42) # set random seed for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee4766",
   "metadata": {},
   "source": [
    "Importing data is the same as what we do in last chapter. The only difference is we further split `train_df` into training data and validation data. Since validation data is used to evaluate the model performance and to choose hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ef660cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "train_df = pd.read_csv('../全连接神经网络/train_data.csv') # import training data\n",
    "test_df = pd.read_csv('../全连接神经网络/test_data.csv')\n",
    "\n",
    "# split train_df into training and validation set\n",
    "train_df, valid_df = train_test_split(train_df, \n",
    "                                      stratify=train_df['noncompliance'], \n",
    "                                      test_size=0.2, \n",
    "                                      random_state=42,\n",
    "                                      shuffle=True)\n",
    "\n",
    "# standardize the input\n",
    "scaler = StandardScaler()\n",
    "X_train_array = scaler.fit_transform(train_df.drop(['noncompliance'], axis=1))\n",
    "X_valid_array = scaler.transform(valid_df.drop(['noncompliance'], axis=1))\n",
    "X_test_array = scaler.transform(test_df.drop(['noncompliance'], axis=1))\n",
    "y_train_array = train_df['noncompliance'].values\n",
    "y_valid_array = valid_df['noncompliance'].values\n",
    "y_test_array = test_df['noncompliance'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b708de15",
   "metadata": {},
   "source": [
    "The procedures of preparing `train_loader` and `test_loader` are the same. For simplicity, we could define `prepare_loader()` function used to transform our array like data into DataLoader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5934df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loader(X_array, y_array, batch_size, shuffle):\n",
    "    \"\"\"\n",
    "    transform array data into DataLoader\n",
    "    params:\n",
    "        X_array: ndarray, feature;\n",
    "        y_array: ndarray, label;\n",
    "        batch_size: int, batch size;\n",
    "        shuffle: bool, change the order of samples;\n",
    "    return:\n",
    "        loader: DataLoader, data including features and labels used in pytorch.\n",
    "    \"\"\"\n",
    "    X_tensor = torch.tensor(X_array, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y_array, dtype=torch.float32)\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return loader\n",
    "\n",
    "# prepare training, validation and test data\n",
    "train_loader = prepare_loader(X_train_array, y_train_array, batch_size=128, shuffle=True)\n",
    "valid_loader = prepare_loader(X_valid_array, y_valid_array, batch_size=128, shuffle=False)\n",
    "test_loader = prepare_loader(X_test_array, y_test_array, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848163b8",
   "metadata": {},
   "source": [
    "## 1 - $\\ell_2$ Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4322b767",
   "metadata": {},
   "source": [
    "Recall the backpropagation of $\\ell_2$ penalty:\n",
    "$J_2 = \\frac{\\lambda}{2n} \\sum_{l} ||W^{[l]}||_{F}^2$ \n",
    "and the derivative is \n",
    "$\\frac{\\partial J_2}{\\partial W^{[l]}} = \\frac{\\lambda}{n} W^{[l]}.$\n",
    "The update step for $\\ell_2$ penalty is \n",
    "$$\n",
    "W^{[l] (t+1)} = W^{[l] (t)} - \\text{lr} \\times (\\text{grad}_{W^{[l]}} + \\lambda \\times W^{[l] (t)}).\n",
    "$$\n",
    "\n",
    "**In the optimizer without momentum** (e.g. `torch.optim.SGD`), we can implement $\\ell_2$ regularization by adding $\\lambda \\times W$ to the gradients, instead of actually modifying the loss function. This can be done by setting the param `weight_decay`, which allows the optimizer to update parameters in the following way: \n",
    "$$\n",
    "\\text{param} = \\text{param} - \\text{lr} \\times (\\text{grad} + \\text{weight decay} * \\text{param})\n",
    "$$\n",
    "\n",
    "**In the optimizer with momentum** (e.g. `torch.optim.Adam`), `weight_decay` and $\\ell_2$ regularization are different, see [Loshchilov and Hutter (2019)](https://arxiv.org/pdf/1711.05101) for more details. The solution is to use `torch.optim.AdamW` optimizer. \n",
    "\n",
    "Another notification is that `weight_decay` would apply on all the model parameters including bias. So, the following function classifies all the parameters into `decay` group and `no_decay` group, then return a list that can be directly passed to `torch.optim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "099d7127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_groups(model, weight_decay=3e-3):\n",
    "    \"\"\"\n",
    "    group parameters that need weight_decay and no weight_decay\n",
    "    params:\n",
    "        model: nn.Module \n",
    "        weight_decay: float, weight_decay for weights parameters\n",
    "    return:\n",
    "        param_groups: list, parameter groups to optimizer\n",
    "    \"\"\"\n",
    "    decay, no_decay = [], []\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'bias' in name or 'bn' in name: # exclude bias and batch norm parameters from weight decay\n",
    "            no_decay.append(param)\n",
    "        else: # all other parameters (weights) will have weight decay\n",
    "            decay.append(param)\n",
    "\n",
    "    param_groups = [\n",
    "        {'params': decay, 'weight_decay': weight_decay}, # set weight_decay for 'decay group'\n",
    "        {'params': no_decay, 'weight_decay': 0.0} # set no weigth_decay for 'no decay group'\n",
    "    ]\n",
    "    return param_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2440030c",
   "metadata": {},
   "source": [
    "We can implement $\\ell_2$ regularization by modifying the optimizer: `optimizer = torch.optim.AdamW(get_param_groups(model, weight_decay=1e-4), lr=3e-4)`. In the following codes, we would see how the l2 norm of all weights would change as weight decay increases. \n",
    "\n",
    "Firstly, we define a function to calculate the l2 norm of all weights in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efc1d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_weights_l2norm(model):\n",
    "    '''calculate l2 norm of all weights'''\n",
    "    total_norm = 0.0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name and param.requires_grad:\n",
    "            total_norm += torch.norm(param, p=2) ** 2\n",
    "    return total_norm.sqrt().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0977fa26",
   "metadata": {},
   "source": [
    "Then, we change `weight_decay` from 1e-4 to 1e-2. This is consistent with our intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fc4f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training weight decay: 0.001\n",
      "Epoch [50/500] Loss: 0.1369\n",
      "Epoch [100/500] Loss: 0.1169\n",
      "Epoch [150/500] Loss: 0.1072\n",
      "Epoch [200/500] Loss: 0.0923\n",
      "Epoch [250/500] Loss: 0.0836\n",
      "Epoch [300/500] Loss: 0.0788\n",
      "Epoch [350/500] Loss: 0.0689\n",
      "Epoch [400/500] Loss: 0.0705\n",
      "Epoch [450/500] Loss: 0.0601\n",
      "Epoch [500/500] Loss: 0.0555\n",
      "Training weight decay: 0.003\n",
      "Epoch [50/500] Loss: 0.1272\n",
      "Epoch [100/500] Loss: 0.1025\n",
      "Epoch [150/500] Loss: 0.0876\n",
      "Epoch [200/500] Loss: 0.0776\n",
      "Epoch [250/500] Loss: 0.0661\n",
      "Epoch [300/500] Loss: 0.0796\n",
      "Epoch [350/500] Loss: 0.0634\n",
      "Epoch [400/500] Loss: 0.0467\n",
      "Epoch [450/500] Loss: 0.0401\n",
      "Epoch [500/500] Loss: 0.0377\n",
      "Training weight decay: 0.005\n",
      "Epoch [50/500] Loss: 0.1304\n",
      "Epoch [100/500] Loss: 0.1065\n",
      "Epoch [150/500] Loss: 0.0934\n",
      "Epoch [200/500] Loss: 0.0845\n",
      "Epoch [250/500] Loss: 0.0819\n",
      "Epoch [300/500] Loss: 0.0768\n",
      "Epoch [350/500] Loss: 0.0696\n",
      "Epoch [400/500] Loss: 0.0648\n",
      "Epoch [450/500] Loss: 0.0587\n",
      "Epoch [500/500] Loss: 0.0688\n",
      "Training weight decay: 0.007\n",
      "Epoch [50/500] Loss: 0.1281\n",
      "Epoch [100/500] Loss: 0.1044\n",
      "Epoch [150/500] Loss: 0.0906\n",
      "Epoch [200/500] Loss: 0.0856\n",
      "Epoch [250/500] Loss: 0.0835\n",
      "Epoch [300/500] Loss: 0.0797\n",
      "Epoch [350/500] Loss: 0.0699\n",
      "Epoch [400/500] Loss: 0.0677\n",
      "Epoch [450/500] Loss: 0.0713\n",
      "Epoch [500/500] Loss: 0.0637\n",
      "Training weight decay: 0.009\n",
      "Epoch [50/500] Loss: 0.1314\n",
      "Epoch [100/500] Loss: 0.1085\n",
      "Epoch [150/500] Loss: 0.0979\n",
      "Epoch [200/500] Loss: 0.0900\n",
      "Epoch [250/500] Loss: 0.0816\n",
      "Epoch [300/500] Loss: 0.0721\n",
      "Epoch [350/500] Loss: 0.0672\n",
      "Epoch [400/500] Loss: 0.0644\n",
      "Epoch [450/500] Loss: 0.0650\n",
      "Epoch [500/500] Loss: 0.0680\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGwCAYAAABcnuQpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABlkklEQVR4nO3deVhUZf8G8HtmGPZFAdkUAUVBRFxww90UNU1x3xI1Xyv3pVJTX1NLc6m3UissdzPSDNwyUUpBUEFBERQXVNxZxIVBEBjg/P4w+UWgMjBwZob7c11cV5x5eOb7BdLb85zzHIkgCAKIiIiItJRU7AKIiIiIKoNhhoiIiLQawwwRERFpNYYZIiIi0moMM0RERKTVGGaIiIhIqzHMEBERkVbTE7uAqlZUVIT79+/DzMwMEolE7HKIiIioHARBQFZWFhwcHCCVvvrci86Hmfv378PR0VHsMoiIiKgC7ty5g3r16r1yjM6HGTMzMwDPvxnm5uZqnVupVOLIkSPo1asX5HK5WufWBOxP++l6j+xP++l6j+yv4hQKBRwdHYv/Hn8VnQ8zL5aWzM3NqyTMGBsbw9zcXGd/SdmfdtP1Htmf9tP1Htlf5ZXnEhFeAExERERajWGGiIiItBrDDBEREWk1hhkiIiLSagwzREREpNUYZoiIiEirMcwQERGRVmOYISIiIq3GMENERERajWGmggqLBEQnP0JshgTRyY9QWCSIXRIREVGNpPOPM6gKIRdSsPRAIlIycwHIsD0pBvYWhljc3wN9PO3FLo+IiKhG4ZkZFYVcSMHkHWf/DjL/LzUzF5N3nEXIhRSRKiMiIqqZGGZUUFgkYOmBRJS1oPTi2NIDiVxyIiIiqkYMMyo4nfyo1BmZfxIApGTm4nTyo+orioiIqIZjmFFBetbLg0xFxhEREVHlMcyowMbMUK3jiIiIqPIYZlTQ1sUS9haGkLxijJFcBs+65tVWExERUU3HMKMCmVSCxf09AOClgeaZshBDAk7i+oOn1VcYERFRDcYwo6I+nvYIGNMKdhYll5LsLQwxu2djWJsa4GraUwxYF4kD5++LVCUREVHNwU3zKqCPpz18Pexw6lo6jkREo1fndvBxtYFMKsGoto6Y/ss5RCc/wvRfziHm5iMs6NcEBnoyscsmIiLSSTwzU0EyqQTtXCzhbS2gnYslZNLnC0825ob4eWI7TOnWEACw7dQtDP8hCncf54hZLhERkc5imKkCejIp5vZxx6ZxrWFhJMf5O0/w1rpIHLuSLnZpREREOodhpgr1aGKL36d3glc9CzzJUeKdLWfw5eEr3CGYiIhIjRhmqpijpTF2T/KBf3snAMC3x65hzMZobqxHRESkJgwz1cBAT4bPBnpi7aiWMNaX4dSNh+i3NhLRNx6KXRoREZHWY5ipRgOaO2D/tI5oZGOKB1l5GL0xGuvDr6OIy05EREQVxjBTzVxtzLBvWkcMalkXhUUCVh66jPd+ikFmjlLs0oiIiLQSw4wIjPX18NXw5vh8UDPoy6T481I6+q2LQMLdTLFLIyIi0joMMyKRSCQY3a4+gqd0gKOlEe4+foYhASexI+oWBIHLTkREROUlapgJCAiAl5cXzM3NYW5uDh8fHxw6dKjMse+//z4kEgm++eab6i2yinnWtcDv0zqjZxNb5BcW4b97L2D2rjhk5xWIXRoREZFWEDXM1KtXDytXrkRMTAxiYmLwxhtvwM/PDxcvXiwxbu/evYiOjoaDg4NIlVYtC2M5Noz1xvw33SGTSrA37j78vjuBpLQssUsjIiLSeKI+m6l///4lPl++fDkCAgIQFRWFpk2bAgDu3buHadOm4fDhw+jXr99r58zLy0NeXl7x5wqFAgCgVCqhVKr3ItsX86lr3gkd6qOZgxlm/RqPa+lPMeDbSCzza4oBze3VMr+q1N2fptH1/gDd75H9aT9d75H9VX7u8pAIGnKBRmFhIXbv3o1x48bh3Llz8PDwQFFREXr27Ak/Pz/MnDkTzs7OmDVrFmbNmvXSeZYsWYKlS5eWOh4YGAhjY+Mq7EB9FPnA9iQpkhTPT5x1tC3CYOci6PEKJyIiqiFycnIwevRoZGZmwtzc/JVjRX9qdkJCAnx8fJCbmwtTU1Ps2bMHHh4eAIBVq1ZBT08PM2bMKPd88+fPxwcffFD8uUKhgKOjI3r16vXab4aqlEolQkND4evrC7lcrta5hxUJWHfsOr4Lu4ETaVJkymph7UgvONauvkBWlf1pAl3vD9D9Htmf9tP1Htlfxb1YWSkP0cOMm5sb4uLi8OTJEwQFBWHcuHEIDw/Hs2fPsGbNGpw9exYSiaTc8xkYGMDAwKDUcblcXmW/SFUxtxzAnD5N0NrFCrN3xeHCfQUGfh+Fr4a3QE8PW7W+12trqcLvnSbQ9f4A3e+R/Wk/Xe+R/VVszvISfeFCX18frq6uaN26NVasWIHmzZtjzZo1iIiIQHp6OurXrw89PT3o6enh1q1b+PDDD+Hs7Cx22dWmu5sNDs7ojBaOtaDILcDE7TFYeegyCgqLxC6NiIhII4geZv5NEATk5eXB398f8fHxiIuLK/5wcHDAnDlzcPjwYbHLrFZ1axnh1/d9ML6DMwBgffh1jN4YjXQFH1ZJREQk6jLTggUL8Oabb8LR0RFZWVnYuXMnwsLCEBISAisrK1hZWZUYL5fLYWdnBzc3N5EqFo++nhRLBjRFG2dLzAuKx+nkR+i7NhJrR7VAh4bWYpdHREQkGlHPzKSlpcHf3x9ubm7o0aMHoqOjERISAl9fXzHL0mj9vOyxf1pHuNuZIeNpHsZsjMZ3x67xYZVERFRjiXpmZtOmTSqNv3nzZtUUomUa1DHFnikdsWjfBfwWexdfHL6CmJuP8NXwFqhtoi92eURERNVK466ZofIx0pfhy2HNsXqIFwz0pDh25QHeWheJuDtPxC6NiIioWjHMaLnhbRwRPKUDnKyMce/JMwxbfxLbTt7kwyqJiKjGYJjRAU0dLHBgeif0aWoHZaGAxfsvYvov5/CUD6skIqIagGFGR5gbyhEwphX+268J9KQS/B6fggHfRuJKKh9WSUREuo1hRodIJBJM7NwAu95vDztzQ9x4kA2/7yIRfPau2KURERFVGYYZHeTtZImDMzqhcyNr5CqL8MGv5zE/OB65ykKxSyMiIlI7hhkdZWVqgK3vtMWsno0gkQC/nL6DIQEncethttilERERqRXDjA6TSSWY1bMxtk9oC0sTfVy8r8Bb6yJx+GKq2KURERGpDcNMDdC5UR0cnNEJ3k61kZVbgPd/isXyg4lQ8mGVRESkAxhmagh7CyPsfK89JnZyAQBsiEjGqB+jkJrJh1USEZF2Y5ipQeQyKf77lgfWj2kFMwM9xNx6jH5rIxCZlCF2aURERBXGMFMD9fG0x4HpndDE3hwPs/Phvzkaa/9K4sMqiYhIKzHM1FDO1ibYM6UDRrZxhCAAX4VexfitZ/AoO1/s0oiIiFTCMFODGcplWDnEC18Oaw5DuRTHrz5Av7URiL31WOzSiIiIyo1hhjDUux72Tu2IBtYmSMnMxYgfTmFzZDIfVklERFqBYYYAAO525tg3rSP6edmjoEjAp78nYvrO88jlsyqJiEjDMcxQMTNDOb4d1RJL+ntALpPgcGI6vkyQ4TIfVklERBqMYYZKkEgkGN/RBb++7wN7C0M8yJVg6A/R+DXmjtilERERlYlhhsrUsn5t7JvSHk1qFSGvoAhzf4vH3N/O82GVRESkcRhm6KVqG+vjPfcizO7hCqkE+DXmLgZ+dwLJGXxYJRERaQ6GGXolqQSY0q0BdvynHaxN9XE5NQv910XiUEKK2KUREREBYJihcurgao2DMzqjrbMlnuYVYPLPZ/HpgUTkF/BhlUREJC6GGSo3W3NDBL7bDu93bQAA2HwiGSN+PIX7T56JXBkREdVkDDOkEj2ZFPPfbIINY1vDzFAP524/Qb+1EQi/+kDs0oiIqIZimKEK8fWwxcHpneFZ1xyPc5QYv+U0vgq9ikI+rJKIiKoZwwxVWH0rY/w2qQNGt6sPQQDW/pWEcZtPI+NpntilERFRDcIwQ5ViKJfh80HN8PWI5jCSyxB5LQP91kYg5uYjsUsjIqIagmGG1GJQy3rYP60jGtYxQZoiDyN+jMKG4zf4sEoiIqpyDDOkNo1szbB/WicMaO6AwiIBy/+4hEk7YpH5TCl2aUREpMMYZkitTAz0sGZkC3w20BP6MikOX0xD/3WRuHAvU+zSiIhIR4kaZgICAuDl5QVzc3OYm5vDx8cHhw4dKn59yZIlcHd3h4mJCWrXro2ePXsiOjpaxIqpPCQSCfzbO+G3yT6oW8sItx/lYHDASfxy+jaXnYiISO1EDTP16tXDypUrERMTg5iYGLzxxhvw8/PDxYsXAQCNGzfGt99+i4SEBERGRsLZ2Rm9evXCgwfc00QbeNWrhYMzOqGHuw3yC4owPzgBH+4+j5z8ArFLIyIiHSJqmOnfvz/69u2Lxo0bo3Hjxli+fDlMTU0RFRUFABg9ejR69uyJBg0aoGnTpvjqq6+gUCgQHx8vZtmkglrG+tgwtjXm9nGDVAIEn72Hgd+dwPUHT8UujYiIdISe2AW8UFhYiN27dyM7Oxs+Pj6lXs/Pz8ePP/4ICwsLNG/e/KXz5OXlIS/v//c5USgUAAClUgmlUr0Xor6YT93zagp19vduRyd4OZhh9q/xuJr2FAPWRWL5wKbo18yu0nNXlK7//ADd75H9aT9d75H9VX7u8pAIIl/EkJCQAB8fH+Tm5sLU1BSBgYHo27dv8eu///47Ro4ciZycHNjb22Pv3r1o06bNS+dbsmQJli5dWup4YGAgjI2Nq6QHKj9FPrAtSYpriucnBTvbFWGgUxH0eCk6ERH9Q05ODkaPHo3MzEyYm5u/cqzoYSY/Px+3b9/GkydPEBQUhI0bNyI8PBweHh4AgOzsbKSkpCAjIwMbNmzA0aNHER0dDRsbmzLnK+vMjKOjIzIyMl77zVCVUqlEaGgofH19IZfL1Tq3Jqiq/goKi7D26HUEHE8GAHjVM8faEc1Rt5aR2t6jPHT95wfofo/sT/vpeo/sr+IUCgWsra3LFWZEX2bS19eHq6srAKB169Y4c+YM1qxZgx9++AEAYGJiAldXV7i6uqJ9+/Zo1KgRNm3ahPnz55c5n4GBAQwMDEodl8vlVfaLVJVzawJ19yeXA/P6eqBNAyvM3nUe8XcVGBgQha+Ht0B397JDalXS9Z8foPs9sj/tp+s9sr+KzVleGndyXxCEEmdWVH2dtMcb7rb4fXonNK9ngSc5Sryz9Qy+OHwZBYVFYpdGRERaRNQws2DBAkRERODmzZtISEjAwoULERYWhrfffhvZ2dlYsGABoqKicOvWLZw9exYTJ07E3bt3MWzYMDHLJjVytDTGr5N8MNbHCQDw3bHr8N90GulZuSJXRkRE2kLUMJOWlgZ/f3+4ubmhR48eiI6ORkhICHx9fSGTyXD58mUMGTIEjRs3xltvvYUHDx4gIiICTZs2FbNsUjMDPRk+9fPE2lEtYawvw6kbD9FvbSSibzwUuzQiItICol4zs2nTppe+ZmhoiODg4GqshsQ2oLkDPOzNMeXnWFxNe4rRG6Mxp7cb3uvcAFKpROzyiIhIQ2ncNTNUs7namGLv1I4Y3LIuCosErDx0Ge/9FIPMHN3co4GIiCqPYYY0jrG+Hv43vDlWDG4GfT0p/ryUjn7rIpBwlw+rJCKi0hhmSCNJJBKMalsfwZM7wNHSCHcfP8OQgJPYEXWLD6skIqISGGZIo3nWtcDv0zvD18MW+YVF+O/eC5i1Kw7ZeXxYJRERPccwQxrPwkiOH/29saCvO2RSCfbF3YffdyeQlJYldmlERKQBGGZIK0gkErzXpSF+ebc9bMwMcC39KQZ8ewL74u6JXRoREYmMYYa0SlsXSxyc0RkdGlrhmbIQM3fG4b97E5BXUCh2aUREJBKGGdI6dcwM8NN/2mHGG66QSIAdUbcxNOAU7jzKEbs0IiISAcMMaSWZVIIPerlhy/g2qG0sR8K9TPRbG4E/E9PELo2IiKoZwwxptW5uNjg4ozNa1q8FRW4BJm6PwcpDfFglEVFNwjBDWs+hlhF2veeDdzo6AwDWh1/H6I3RSFfwYZVERDUBwwzpBH09KRb3b4rvRreCqYEeTic/Qt+1kTh5PUPs0oiIqIoxzJBO6edlj/3TOsLdzgwZT/MwZmM0vjt2DUVF3DWYiEhXMcyQzmlQxxR7pnTEUO96KBKALw5fwX+2ncHj7HyxSyMioirAMEM6yUhfhi+HNcfqIV4w0JPi2JUHeGtdJOLuPAEAFBYJiE5+hNgMCaKTH6GQZ26IiLSWntgFEFWl4W0c4VnXAlN+jsXNhzkYtv4kBresh/CkB0jNzAUgw/akGNhbGGJxfw/08bQXu2QiIlIRz8yQzvNwMMf+6Z3wpqcdlIUCdsXc+TvI/L/UzFxM3nEWIRdSRKqSiIgqimGGagRzQznWjWoJM8OyT0a+WGRaeiCRS05ERFqGYYZqjDM3HyMrt+ClrwsAUjJzcTr5UfUVRURElcYwQzVGelb5NtEr7zgiItIMDDNUY9iYGap1HBERaQaGGaox2rpYwt7CEJJXjLG3MERbF8tqq4mIiCqPYYZqDJlUgsX9PQDgpYFmQd8mkElfFXeIiEjTMMxQjdLH0x4BY1rBzqLkUpLk7/xy/cFTEaoiIqLK4KZ5VOP08bSHr4cdTl1Lx5GIaPTq3A4Z2QWYtSsO3x69ht5N7dDE3lzsMomIqJx4ZoZqJJlUgnYulvC2FtDOxRJ+LRzg62GLgiIBc3+LR0FhkdglEhFROTHMEAGQSCRYPtATFkZyJNzLxA/Hb4hdEhERlRPDDNHfbMwN8clbzy8QXvNnEq6lZ4lcERERlQfDDNE/DG5VF93c6iC/sAhzfovnow2IiLQAwwzRP0gkEqwY3AxmBno4d/sJNkcmi10SERG9hqhhJiAgAF5eXjA3N4e5uTl8fHxw6NAhAIBSqcS8efPQrFkzmJiYwMHBAWPHjsX9+/fFLJlqAHsLIyzs1wQA8OWRK7jB27WJiDSaqGGmXr16WLlyJWJiYhATE4M33ngDfn5+uHjxInJycnD27FksWrQIZ8+eRXBwMK5evYoBAwaIWTLVECPaOKKTqzXyCoowLygeRVxuIiLSWKKGmf79+6Nv375o3LgxGjdujOXLl8PU1BRRUVGwsLBAaGgohg8fDjc3N7Rv3x7r1q1DbGwsbt++LWbZVAO8WG4y1pfhzM3H2H7qptglERHRS2jMpnmFhYXYvXs3srOz4ePjU+aYzMxMSCQS1KpV66Xz5OXlIS8vr/hzhUIB4PmylVKpVGvNL+ZT97yaoqb3Z2cmx9xejbDk98tYFXIZnV0tUd/SuDpLrLSa/jPUdrreH6D7PbK/ys9dHhJBEEQ9f56QkAAfHx/k5ubC1NQUgYGB6Nu3b6lxubm56NSpE9zd3bFjx46XzrdkyRIsXbq01PHAwEAYG2vXX0QkviIB+C5RhmsKCRqZF2GqR1Hxow+IiKjq5OTkYPTo0cjMzIS5+at3ZVc5zGzbtg3W1tbo168fAGDu3Ln48ccf4eHhgV9++QVOTk4qFZufn4/bt2/jyZMnCAoKwsaNGxEeHg4PD4/iMUqlEsOGDcPt27cRFhb2yqbKOjPj6OiIjIyM134zVKVUKhEaGgpfX1/I5XK1zq0J2N9ztx7m4K3vTiJXWYRPBzTBqDaO1Vhl5fBnqN10vT9A93tkfxWnUChgbW1drjCj8jLT559/joCAAADAqVOn8O233+Kbb77B77//jtmzZyM4OFil+fT19eHq6goAaN26Nc6cOYM1a9bghx9+APD8GzV8+HAkJyfj6NGjr23IwMAABgYGpY7L5fIq+0Wqyrk1QU3vz9XOAnN6u+Oz3xOx+nASenjYo24to2qssPJq+s9Q2+l6f4Du98j+KjZneal8AfCdO3eKw8fevXsxdOhQvPfee1ixYgUiIiJUna4UQRCKz6y8CDJJSUn4888/YWVlVen5iSpifAdneDvVxtO8AnwcFA+RV2eJiOgfVA4zpqamePjwIQDgyJEj6NmzJwDA0NAQz549U2muBQsWICIiAjdv3kRCQgIWLlyIsLAwvP322ygoKMDQoUMRExODn3/+GYWFhUhNTUVqairy8/NVLZuoUmRSCVYN8YK+nhQRSRnYHXtX7JKIiOhvKi8z+fr6YuLEiWjZsiWuXr1afO3MxYsX4ezsrNJcaWlp8Pf3R0pKCiwsLODl5YWQkBD4+vri5s2b2L9/PwCgRYsWJb7u2LFj6Natm6qlE1WKq40pPvBtjJWHLuOz3xPRpVEd2FkYil0WEVGNp3KY+e677/Df//4Xd+7cQVBQUPHST2xsLEaNGqXSXJs2bXrpa87OzjyVTxpnYicXHEpIwfm7mVi4JwEbx7WGhLc3ERGJSuUwo1AosHbtWkilJVeolixZgjt37qitMCJNpCeT4othzdFvbQT+upyOfXH3MbBlXbHLIiKq0VS+ZsbFxQUZGRmljj969AguLi5qKYpIkzW2NcOMNxoBAJYcuIj0rFyRKyIiqtlUDjMvW/p5+vQpDA15/QDVDJO6NURTB3M8yVHik70XuSRKRCSici8zffDBBwCeP7Pmk08+KbGbbmFhIaKjo0tdqEukq+QyKVYP9YLftycQcjEVfySkop+XvdhlERHVSOUOM+fOnQPw/MxMQkIC9PX1i1/T19dH8+bN8dFHH6m/QiIN1dTBAlO6NcTao9fwyb4LaN/AElampTdsJCKiqlXuMHPs2DEAwDvvvIM1a9ao/dEARNpo2huNcPhiGq6kZWHJgUSsG9VS7JKIiGocla+Z2bJlC4MM0d/09aT4YpgXpBLgwPn7OHwxVeySiIhqHJVvzc7OzsbKlSvx119/IT09HUVFRSVev3HjhtqKI9IGXvVq4b0uDbE+/Dr+u/cC2rlYopax/uu/kIiI1ELlMDNx4kSEh4fD398f9vb23DCMCMCsno0QmpiK6w+y8envifhqeAuxSyIiqjFUDjOHDh3CwYMH0bFjx6qoh0grGcplWD20OYauP4ngs/fwlpc93nC3FbssIqIaQeVrZmrXrg1LS8uqqIVIq3k71cZ/Oj7fOHJB8AUocpUiV0REVDOoHGY+++wzfPLJJ8jJyamKeoi02oe93OBsZYxURS4+P3hJ7HKIiGqEci0ztWzZssS1MdeuXYOtrS2cnZ0hl8tLjD179qx6KyTSIkb6Mqwa4oURP0Zh55k76Odlj86N6ohdFhGRTitXmBk4cGAVl0GkO9o1sMI4HydsO3ULHwcl4PDsLjA1UPnyNCIiKqdy/Qm7ePHiqq6DSKfM7eOOvy6n4+7jZ1h16DI+G+gpdklERDpL5WtmiOj1TAz0sGqIFwDgp6hbOHX9ocgVERHprgrfzfTvDysrK9StWxddu3bFli1bqqJWIq3S0dUao9rWBwDMC4pHTn6ByBUREekmlcPMJ598AqlUin79+mHp0qVYsmQJ+vXrB6lUiqlTp6Jx48aYPHkyNmzYUBX1EmmVBX3dYW9hiNuPcvDl4atil0NEpJNUvioxMjISy5Ytw6RJk0oc/+GHH3DkyBEEBQXBy8sLa9euxbvvvqu2Qom0kZmhHCsGN8P4LWew5WQy+jazQ2tn7tNERKROKp+ZOXz4MHr27FnqeI8ePXD48GEAQN++ffmMJqK/dXOzwVDvehAEYO5v8chVFopdEhGRTlE5zFhaWuLAgQOljh84cKB4Z+Ds7GyYmZlVvjoiHbGonwdszAxwIyMbX//J5SYiInVSeZlp0aJFmDx5Mo4dO4a2bdtCIpHg9OnT+OOPP7B+/XoAQGhoKLp27ar2Yom0lYWxHMsHNcO722Ow4fgNvOlpjxaOtcQui4hIJ6h8Zubdd99FeHg4TExMEBwcjN9++w3GxsYIDw/Hf/7zHwDAhx9+iF27dqm9WCJt5uthC78WDigSgDm7zyOvgMtNRETqUKFtSTt27MinZhNVwJL+TXHiWgaS0p9i3V/X8FFvN7FLIiLSeuU6M6NQKEr896s+iOjlapvo41O/57sBB4Rfx4V7mSJXRESk/coVZmrXro309HQAQK1atVC7du1SHy+OE9Gr9W1mj77N7FBYJGDOb/HILygSuyQiIq1WrmWmo0ePFt+pdOzYsSotiKgm+NTPE6euP8SlFAUCwq5jZs9GYpdERKS1yhVm/nlnEu9SIqo8a1MDLBnQFDN3xuHbY0no7WkLdztzscsiItJKFXrQZEREBMaMGYMOHTrg3r17AICffvoJkZGRai2OSJcNaO6Ank1soSwUMGd3PAoKudxERFQRKoeZoKAg9O7dG0ZGRjh79izy8vIAAFlZWfj888/VXiCRrpJIJPh8kCfMDfWQcC8TP0Zw12wioopQOcwsW7YM69evx4YNGyCXy4uPd+jQAWfPnlVrcUS6zsbcEJ/0bwoA+ObPJFxLzxK5IiIi7aNymLly5Qq6dOlS6ri5uTmePHmi0lwBAQHw8vKCubk5zM3N4ePjg0OHDhW/HhwcjN69e8Pa2hoSiQRxcXGqlkuk8Ya0qotubnWQX1CEOb/Fo7BIELskIiKtonKYsbe3x7Vr10odj4yMRIMGDVSaq169eli5ciViYmIQExODN954A35+frh48SKA58946tixI1auXKlqmURa4/lyUzOYGujh3O0n2HIiWeySiIi0iso7AL///vuYOXMmNm/eDIlEgvv37+PUqVP46KOP8Mknn6g0V//+/Ut8vnz5cgQEBCAqKgpNmzaFv78/AODmzZvlnjMvL6/4Oh7g/zf8UyqVUCqVKtX3Oi/mU/e8moL9VZ86Jnr4uE9j/HdfIr44fAVdG1nC2cqk0vNqUo9Vgf1pP13vkf1Vfu7ykAiCoPI57YULF+Lrr79Gbm4uAMDAwAAfffQRPvvsM1WnKlZYWIjdu3dj3LhxOHfuHDw8PIpfu3nzJlxcXHDu3Dm0aNHilfMsWbIES5cuLXU8MDAQxsbGFa6PqKoJAvD9JSmuZkrR0EzAtKaFkErEroqISBw5OTkYPXo0MjMzYW7+6q0ryh1m/vzzT3Ts2BFGRkbFb5KYmIiioiJ4eHjA1NS0QsUmJCTAx8cHubm5MDU1RWBgIPr27VtijCphpqwzM46OjsjIyHjtN0NVSqUSoaGh8PX1LXExtK5gf9Xv7uNn6PftSeTkF+KTfu7wb1+/UvNpYo/qxP60n673yP4qTqFQwNraulxhptzLTL169YK+vj7atm2L7t2744033oCPjw/09fUrVaybmxvi4uLw5MkTBAUFYdy4cQgPDy9xZkYVBgYGMDAwKHVcLpdX2S9SVc6tCdhf9XGxkePjN93xyb6L+DI0Cb5N7eFoWfkziprUY1Vgf9pP13tkfxWbs7zKfQHwnTt3sGHDBjRu3Bg7duxA9+7dUatWLfTo0QPLli3DiRMnUFBQoHKx+vr6cHV1RevWrbFixQo0b94ca9asUXkeIl0xpp0T2rpYIie/EPOC4lGBlWAiohql3GGmbt268Pf3x8aNG3H9+nXcunUL69evh5OTEzZv3owuXbqo5UGTgiCUWCYiqmmkUglWD/GCoVyKk9cf4pfTd8QuiYhIo6l8N9MLjo6O6NixY/E1Kg8fPkRhYaFKcyxYsABvvvkmHB0dkZWVhZ07dyIsLAwhISEAgEePHuH27du4f/8+gOd73ACAnZ0d7OzsKlo6kcZztjbBR73csOzgJXz+xyV0dauDurWMxC6LiEgjqbTPzI0bN7B582b4+/ujXr16aNWqFYKDg+Hp6YlDhw7h8ePHKr15Wloa/P394ebmhh49eiA6OhohISHw9fUFAOzfvx8tW7ZEv379AAAjR45Ey5YtsX79epXeh0gbvdPRBa3q18LTvALMD07gchMR0UuU+8yMk5MTFAoFOnXqhC5dumD69Onw9vaGTCar8Jtv2rTpla+PHz8e48ePr/D8RNpMJpVg9dDm6Ls2AsevPsBvsXcxrLWj2GUREWmccp+ZeXEdi0QigUwmg0wmg1RaoYduE1E5udqYYnbPxgCAz35PRJoiV+SKiIg0T7nTSGpqKk6dOoW+ffsiOjoa/fr1Q+3atfHWW2/hyy+/xJkzZ1BUVFSVtRLVSO92dkHzehZQ5BZg4R4uNxER/ZtKp1bc3d0xadIk7Nq1q0S4OX36NHr27AlLS8uqqpOoxtKTSbF6aHPIZRL8eSkd+8/fF7skIiKNUuF1orS0NMTHxyM+Ph7nz59HVlYWb6kmqiJudmaY/kYjAMDi/RfxIIv/rxERvVDuMJOeno5ff/0VU6ZMQZMmTeDg4IBx48YhMTERI0eOxNGjR/HkyZMqLJWoZpvcrSE87M3xJEeJT/ZdELscIiKNUe67mezs7CCXy9G6dWsMGTIE3bp1K/GsJiKqWnKZFF8M84Lftydw6EIq/khIQd9m9mKXRUQkunKHmUOHDqFTp04wMTGpynqI6BWaOlhgcreGWHf0GhbtvYD2DaxgaVK556MREWm7ci8z9e7dm0GGSANMe8MVjW1N8TA7H0v2XxS7HCIi0XGjGCItY6AnwxdDm0MqAfafv48jF1PFLomISFQMM0RaqLljLbzXpSEAYOHeC8jMUYpcERGReBhmiLTUrJ6N0KCOCR5k5eHT3xPFLoeISDTlCjOWlpbIyMgAAEyYMAFZWVlVWhQRvZ6hXIYvhnpBIgGCzt7FsSvpYpdERCSKcoWZ/Px8KBQKAMC2bduQm8vnwxBpAm8nS0zo6AIAWBCcAEUul5uIqOYp163ZPj4+GDhwILy9vSEIAmbMmPHS/WU2b96s1gKJ6NU+6uWGPy+l4dbDHKz44xJWDPYSuyQiompVrjMzO3bsQN++ffH06VNIJBJkZmbi8ePHZX4QUfUy0pdh1ZDnAeaX03cQmZQhckVERNWrXGdmbG1tsXLlSgCAi4sLfvrpJ1hZWVVpYURUfu0bWGGsjxO2n7qFeUHxODy7C0wNyr0nJhGRVlP5bqbk5GQGGSINNK+PO+rWMsK9J8+wOuSy2OUQEVWbCt2aHR4ejv79+8PV1RWNGjXCgAEDEBERoe7aiEgFJgZ6xctN20/dQtSNhyJXRERUPVQOMzt27EDPnj1hbGyMGTNmYNq0aTAyMkKPHj0QGBhYFTUSUTl1amSNUW0dAQDzguLxLL9Q5IqIiKqeyovqy5cvx+rVqzF79uziYzNnzsRXX32Fzz77DKNHj1ZrgUSkmvl9myDsygPcepiDr/+6hhZiF0REVMVUPjNz48YN9O/fv9TxAQMGIDk5WS1FEVHFmRvK8fngZgCAraduIZl7XBKRjlM5zDg6OuKvv/4qdfyvv/6Co6OjWooiosrp7maDIa3qQRCAwGsy5Cq53EREukvlZaYPP/wQM2bMQFxcHDp06ACJRILIyEhs3boVa9asqYoaiagCPnnLA8evpiP9aT7WHbuOBf2ail0SEVGVUDnMTJ48GXZ2dvjf//6HX3/9FQDQpEkT7Nq1C35+fmovkIgqxsJYjk8HeGByYBw2Rt5EP6+6aO5YS+yyiIjUrkK7ag0aNAiDBg1Sdy1EpGY9m9iglVURzj6UYs5v53FgeicY6MnELouISK0qtM8MEWmPIS5FsDLRx9W0p/j26DWxyyEiUjuGGSIdZyoHFr/lDgD4Puw6LtzLFLkiIiL1YpghqgHe9LTDm552KCwSMPe3eCgLi8QuiYhIbRhmiGqIT/08UdtYjsQUBQLCrotdDhGR2jDMENUQdcwMsGTA89uz1x1NwpVU7qZHRLpB5TAjCAJ2796NKVOmYOjQoRg8eHCJD1UEBATAy8sL5ubmMDc3h4+PDw4dOlTivZYsWQIHBwcYGRmhW7duuHjxoqolE9HfBjR3QM8mNlAWCpjz23kUcLmJiHSAymFm5syZ8Pf3R3JyMkxNTWFhYVHiQxX16tXDypUrERMTg5iYGLzxxhvw8/MrDiyrV6/GV199hW+//RZnzpyBnZ0dfH19kZXFf1ESVYREIsHyQc1gbqiH+LuZ2BDBR5AQkfZTeZ+ZHTt2IDg4GH379q30m//7GU/Lly9HQEAAoqKi4OHhgW+++QYLFy4sPuOzbds22NraIjAwEO+//36l35+oJrI1N8Sitzww57d4fP3nVfh62MLVxlTssoiIKkzlMGNhYYEGDRqovZDCwkLs3r0b2dnZ8PHxQXJyMlJTU9GrV6/iMQYGBujatStOnjz50jCTl5eHvLy84s8VCgUAQKlUQqlUqrXmF/Ope15Nwf6038t69POyxYHzVjie9BBzdsfhl4ltIZNKxCixUnT9Z6jr/QG63yP7q/zc5SERBEFQZfJt27YhJCQEmzdvhpGRkcrF/VtCQgJ8fHyQm5sLU1NTBAYGom/fvjh58iQ6duyIe/fuwcHBoXj8e++9h1u3buHw4cNlzrdkyRIsXbq01PHAwEAYGxtXul4iXfE4D1hxXoa8QgkGOhWiu4NKfxQQEVWpnJwcjB49GpmZmTA3N3/lWJXPzAwbNgy//PILbGxs4OzsDLlcXuL1s2fPqjSfm5sb4uLi8OTJEwQFBWHcuHEIDw8vfl0iKfmvRUEQSh37p/nz5+ODDz4o/lyhUMDR0RG9evV67TdDVUqlEqGhofD19S31fdAF7E/7va5HWb27WLQ/ESH35Zg2qAOcrLQr8Ov6z1DX+wN0v0f2V3EvVlbKQ+UwM378eMTGxmLMmDGwtbV9ZbAoD319fbi6ugIAWrdujTNnzmDNmjWYN28eACA1NRX29vbF49PT02Fra/vS+QwMDGBgYFDquFwur7JfpKqcWxOwP+33sh7H+DgjJDENJ649xIJ9idj5bntItXC5Sdd/hrreH6D7PbK/is1ZXiqHmYMHD+Lw4cPo1KmTql9aLoIgIC8vDy4uLrCzs0NoaChatmwJAMjPz0d4eDhWrVpVJe9NVNNIJBKsHOyF3t8cx+nkR9gRfQtjfZzFLouISCUq35rt6OiotuWaBQsWICIiAjdv3kRCQgIWLlyIsLAwvP3225BIJJg1axY+//xz7NmzBxcuXMD48eNhbGyM0aNHq+X9iQhwtDTGvD7Pn9208tBl3HmUI3JFRESqUTnM/O9//8PcuXNx8+bNSr95Wloa/P394ebmhh49eiA6OhohISHw9fUFAMydOxezZs3ClClT0Lp1a9y7dw9HjhyBmZlZpd+biP6ff3sntHW2RE5+IT4OjoeK9wUQEYlK5WWmMWPGICcnBw0bNoSxsXGpNa1Hjx6Ve65Nmza98nWJRIIlS5ZgyZIlqpZJRCqQSiVYNdQLfb45jhPXHmLnmTsY1ba+2GUREZWLymHmm2++qYIyiEhsLtYmmNPbDcsOXsLyg5fQtXEdONSq/PYLRERVTaUwo1QqERYWhkWLFlXJxnlEJK53Orrgj4QUnL39BPODE7D1nTaVvmORiKiqqXTNjFwux549e6qqFiISmUwqweqhzaGvJ0X41QcIOntP7JKIiF5L5QuABw0ahL1791ZBKUSkCVxtTDGrZyMAwKcHLiJNkStyRUREr6byNTOurq747LPPcPLkSXh7e8PExKTE6zNmzFBbcUQkjvc6N0DIhVTE383Ewj0XsGGsN5ebiEhjqRxmNm7ciFq1aiE2NhaxsbElXpNIJAwzRDpATybF6qFe6L8uEn9eSsP+8/fh16Ku2GUREZVJ5TCTnJxcFXUQkYZxtzPHtO6N8PWfV7Fk/0V0aGiNOmalHxVCRCQ2la+Z+SdBELi5FpEOm9K9IZrYm+NxjhKL918QuxwiojJVKMxs374dzZo1g5GREYyMjODl5YWffvpJ3bURkcjkMim+GOoFPakEfySk4o+EFLFLIiIqReUw89VXX2Hy5Mno27cvfv31V+zatQt9+vTBpEmT8PXXX1dFjUQkIs+6FpjcrSEA4JN9F/AoO1/kioiISlL5mpl169YhICAAY8eOLT7m5+eHpk2bYsmSJZg9e7ZaCyQi8U17wxWHL6biatpTLD1wEWtGthS7JCKiYiqfmUlJSUGHDh1KHe/QoQNSUngKmkgXGejJ8MXQ5pBKgH1x9xGamCZ2SURExVQOM66urvj1119LHd+1axcaNWqklqKISPM0d6yFd7s8f4zJwj0JyMxRilwREdFzKi8zLV26FCNGjMDx48fRsWNHSCQSREZG4q+//ioz5BCR7pjdszFCL6bhRkY2PjuYiC+HNRe7JCIi1c/MDBkyBNHR0bC2tsbevXsRHBwMa2trnD59GoMGDaqKGolIQxjKZfhimBckEuC32Ls4diVd7JKIiFQ/MwMA3t7e2LFjh7prISIt4O1kiXc6uGDziWQsCE7AkdldYGYoF7ssIqrBKrVpHhHVTB/1boz6lsZIyczF539cFrscIqrhyh1mpFIpZDLZKz/09Cp0ooeItIyxvh5WDfECAPxy+jZOXMsQuSIiqsnKnT727Nnz0tdOnjyJdevW8dEGRDWIT0Mr+Ld3wk9RtzAvKB6HZ3WBiQH/QUNE1a/cf/L4+fmVOnb58mXMnz8fBw4cwNtvv43PPvtMrcURkWab96Y7jl5Ox93Hz7A65DKW+nmKXRIR1UAVumbm/v37ePfdd+Hl5YWCggLExcVh27ZtqF+/vrrrIyINZmqgh5VDmgEAtp26hegbD0WuiIhqIpXCTGZmJubNmwdXV1dcvHgRf/31Fw4cOABPT/5rjKim6tyoDka2cQQAzA2Kx7P8QpErIqKaptxhZvXq1WjQoAF+//13/PLLLzh58iQ6d+5clbURkZZY0K8J7MwNcethDv535IrY5RBRDVPua2Y+/vhjGBkZwdXVFdu2bcO2bdvKHBccHKy24ohIO5gbyrFicDO8s/UMNp1IxpvN7OHtVFvssoiohih3mBk7diwkEklV1kJEWqy7uw0Gt6qL4LP3MPe38zg4ozMM5TKxyyKiGqDcYWbr1q1VWAYR6YJP3vJARFIGrj/Ixjd/JuHjN93FLomIagDuAExEalPLWB/LBz6/IeDH49dx/s4TcQsiohqBYYaI1KpXUzv0b+6AIgGY+1s88gp4dxMRVS2GGSJSu6UDmsLKRB9X0rLw3dFrYpdDRDqOYYaI1M7SRB+f/r0b8Pdh13HxfqbIFRGRLhM1zKxYsQJt2rSBmZkZbGxsMHDgQFy5UnKPirS0NIwfPx4ODg4wNjZGnz59kJSUJFLFRFRefZvZoU9TOxQUCZizOx7KwiKxSyIiHaVymCkqKvsPpKKiIty+fVulucLDwzF16lRERUUhNDQUBQUF6NWrF7KzswEAgiBg4MCBuHHjBvbt24dz587ByckJPXv2LB5DRJpJIpHgs4GeqGUsR2KKAuvDrotdEhHpqHKHGYVCgeHDh8PExAS2trZYvHgxCgv//8K+Bw8ewMXFRaU3DwkJwfjx49G0aVM0b94cW7Zswe3btxEbGwsASEpKQlRUFAICAtCmTRu4ubnh+++/x9OnT/HLL7+o9F5EVP3qmBlgSf+mAIC1R5NwNS1L5IqISBeVe5+ZRYsW4fz58/jpp5/w5MkTLFu2DLGxsQgODoa+vj6A52dSKiMz8/m6uqWlJQAgLy8PAGBoaFg8RiaTQV9fH5GRkZg4cWKpOfLy8oq/DngewgBAqVRCqVRWqr5/ezGfuufVFOxP+2lCj32b1sE+N2scu5KBj36Nw65320JPpp4Vbk3oryrpen+A7vfI/io/d3lIhHImECcnJ2zbtg3dunUDADx8+BD9+vWDhYUF9u/fjydPnsDBwaHE2RpVCIIAPz8/PH78GBEREQCeN9KoUSO0bdsWP/zwA0xMTPDVV19h/vz56NWrFw4fPlxqniVLlmDp0qWljgcGBsLY2LhCtRFR5TzJA1ael+FZoQQD6heiR93K/cOHiHRfTk4ORo8ejczMTJibm79ybLnDjImJCS5cuFBiKSkrKwu9e/eGkZERNm7cCFdX1wqHmalTp+LgwYOIjIxEvXr1io/HxsbiP//5D86fPw+ZTIaePXtCKn3+r7o//vij1DxlnZlxdHRERkbGa78ZqlIqlQgNDYWvry/kcrla59YE7E/7aVKPv529h/l7LkJfT4r9U3zQsI5JpefUpP6qgq73B+h+j+yv4hQKBaytrcsVZsq9zOTo6IhLly6VCDNmZmY4cuQIevXqhUGDBlW44OnTp2P//v04fvx4iSADAN7e3oiLi0NmZiby8/NRp04dtGvXDq1bty5zLgMDAxgYGJQ6LpfLq+wXqSrn1gTsT/tpQo8j2zrh0MV0HL/6AAv2XsTuSR0gk6rneW+a0F9V0vX+AN3vkf1VbM7yKvfCda9evbBly5ZSx01NTXH48OES17WUlyAImDZtGoKDg3H06NFXXkBsYWGBOnXqICkpCTExMfDz81P5/YhIPBKJBCsGN4OpgR7O3n6CrSdvil0SEemIcp+ZWbp0Ke7fv1/ma2ZmZvjzzz+L70Iqr6lTpyIwMBD79u2DmZkZUlNTATwPLkZGRgCA3bt3o06dOqhfvz4SEhIwc+ZMDBw4EL169VLpvYhIfHVrGWF+X3cs3HMBXxy+jB7uNnC2rvxyExHVbOU+M1O7dm00bdr0pa8/fvwY27ZtU+nNAwICkJmZiW7dusHe3r74Y9euXcVjUlJS4O/vD3d3d8yYMQP+/v68LZtIi41uWx8dGlohV1mEeUHxKCrixcA1VWGRgOjkR4jNkCA6+REK+btAFVTuMzOv8+jRI2zbtg2bN28u99eU59rjGTNmYMaMGZUpjYg0iEQiwcrBXuj9zXFEJz/Cz9G34O/jLHZZVM1CLqRg6YFEpGTmApBhe1IM7C0Msbi/B/p42otdHmkZPpuJiKpdfStjzOvjBgBYcegy7jzKEbkiqk4hF1IwecfZv4PM/0vNzMXkHWcRciFFpMpIWzHMEJEoxvo4o62zJXLyCzE/OKHSm26SdigsErD0QCLK+mm/OLb0QCKXnEglDDNEJAqpVIJVQ71goCdF5LUM7DpzR+ySqApl5SoRdeMhFu+/UOqMzD8JAFIyc3E6+VH1FUdar9zXzAwePPiVrz958qSytRBRDeNibYKPerlh+R+XsPzgJXR1qwN7CyOxy6JKynymxMV7mbhwPxMJ9xS4cC8TyRmqPRw4PevlgYfo38odZiwsLF77+tixYytdEBHVLBM6ueCPCyk4d/sJ5gcnYMv4NpBI1LOZHlW9Jzn5uHBPgYR7mbjwd4C59bDsa6Dq1jKCvYUhYm49fu28Nmaq711GNVe5w0xZG+YREVWWTCrBF0O90HdNJMKuPEDw2XsY4l3v9V9I1e5Rdv7/h5Z7mUi4l4m7j5+VOdbR0gieDhbwrGuBZnUt0NTBHFamBigsEtBp1VGkZuaWed0MANQykqOti2XVNUI6R223ZhMRVZSrjRlm9myELw5fwdIDF9G5kTVszPkvczE9yMorEVou3MvE/Zdc6+JkZVwcWp4HGHPUMtYvc6xMKsHi/h6YvOMsJECZgebJMyV+PH4Dk7o24Fk6KheGGSLSCO93aYCQC6lIuJeJhXsv4Ed/b/5FVk3SFLlIuPt8iehFeElT5JU5toG1CTzrPg8snnUt0NTBAhZGqj2Tp4+nPQLGtPrHPjPP2VsYwrOuBUIT07Aq5DLSFLn45C0PSNX0DC/SXQwzRKQR9GRSfDHMC/3XRSI0MQ0H4lMwoLmD2GXpFEEQkJKZW/KMy30FHmSVDi4SCdCwjik8HcyLz7p4OJjDzFA9DxPs42kPXw87nLqWjiMR0ejVuR18XG0gk0qwMeIGlh28hK0nb+JBVh7+N7w5DOUytbwv6SaGGSLSGO525pja3RXf/JmExfsuoENDK1ibGohdllYSBAH3njz7xzLR87uKHmbnlxorlQCuNqb/v1RU1wIe9uYwMajavyJkUgnauVji4SUB7Vwsi5+iPrFzA9iYG+LDX+NwMCEFD7Pz8OPY1jBXU5Ai3cMwQ0QaZUo3V4RcSMXl1Cws3ncR373dSuySNJ4gCLjz6BkS/g4uF/9eLnqcoyw1ViaVoJGNKZrVtUCzes+XiTzszWGkr1lnPgY0d4CViT7e/ykWUTceYfj6U9g2oS1seS0VlYFhhog0ir6eFF8Oaw6/707gYEIK3kpIwZvN+KyeF4qKBNx6lPM8tPzj4lxFbkGpsXKZBI1tzZ7fTfT3WRd3OzOtWbLp6GqNXe+3x/gtZ3A5NQuDvz+JbRPawNXGTOzSSMMwzBCRxvGsa4HJXRvi22PXsGjfBbRvYIXaJmXfHaPLiooEpD0D9p9PwaXUp0i4l4nE+wpk5ZUOLvoyKdztzdDU4XloaVbXAo3tTGGgpx3B5WWaOlggeHIHjN18GskZ2Ri6/hQ2jWsDb6faYpdGGoRhhog00vQerjh8MRVJ6U+x9MBFfDOypdglVanCIgHXHzwtcSt04n0FsvP1gLiEEmP19aRoYm+OZnXN/97DxQKNbc2gr6ebT6hxtDRG0OQOmLD1DOLuPMHbG6Pw7ahW6OlhK3ZppCEYZohIIxnoyfDFsOYY/P0J7I27j7e8HHTmL6+CwiJce/D0+e3Qf99RlHhfgWfKwlJj5VIBnnVrwatereKlIlcbU8hluhlcXsbSRB+B77bD1J/P4tiVB3jvpxh8PqgZRratL3ZppAEYZohIY7VwrIV3OzfAD8dvYMGeBLRxsVR5TxOxKQuLcDUt6+/boZ9v+38pRYG8gqJSY431ZWj6963Qng4WaGJrgssxx9G/XzvI5drVd1Uw1tfDj2NbY0FwAnbH3sXHwQlIU+RhRg9X7klUwzHMEJFGm+3bGKGJabiRkY1lvyfii2HNxS7ppfIKCnE19enfD1h8ftblckoW8gtLBxdTA73i4PLidmgXa5Pi25MBQKlUIol/R5cgl0mxeqgXbM0N8e2xa/j6z6tIy8rFZ36eJb53VLMwzBCRRjOUy7B6qBeG/XAKu2Pvop+XPbq52YhdFnKVhbiSmlXiAYtXUrOgLCy9Qb+ZoR48HZ7fCv38rIs5nK1MuLNtBUkkEnzU2w225gb4ZP9FBEbfxoOsPKwb1VJr7tQi9WKYISKN19rZEuM7OGPLiZtYEJyAw7O7qG0n2vJ4ll+IS6nPN517vu2/AklpWSgoKh1cLIzkxWdaPP++QLe+pTGXQaqAv48z6pgZYMbOOIQmpuHtjdHYNK71S58LRbqLYYaItMKc3m7461I6bj/KwYpDl/H5oGZV8j45+QVIvK8osWvutQdPUVhGcLE00S8+0/IiwNSrbcTgUo36eNpjx38MMHHbGcTeeoyhf2+uV7eWkdilUTVimCEirWCsr4dVQ7wwakMUAqNvo29TOwBFiM2QwCr5UfFzfVTxNK8AF/++m+jFLdHXHzyFUMajnK1NDdDs74crvrjOxd7CkMFFA7R1scTuSR0wbvNpXEt/iiHfn8S2CW3hZsfN9WoKhhki0ho+Da0wpn197Ii6jXFbTuP55SkybE+Kgb2FIRb390Afz7J3C1bkKnHhXiYu/n1H0YX7mUjOyC4zuNiaG8DTwaLExbm25gYMLhrMzc4MwVOeB5qk9KcYuv4kNoxtjfYNrMQujaoBwwwRaRVvJ0vsiLqNf19nm5qZi8k7ziJgTCu0b2CFi38vFb3Y9v/mw5wy57O3MPxHaHl+5sXGjM//0UYOtYywe5IP3t0egzM3H2Ps5tNYM6IFH4dRAzDMEJHWKCwSsDrkcpmvvcg2U38+WyrovFC3llGJ0OJZ14JP5dYxtYz18dN/2mHGL+dwJDENUwLPYumAphjr4yx2aVSFGGaISGucTn6ElMzcV455EWTqWxoXh5YXW/5b1sDnO9VEhnIZAsZ445N9F/Bz9G18su8i0hS5+KiXG5cKdRTDDBFpjfSsVweZF1YO5jb3NZ1MKsGygZ6wMzfE/0Kv4rtj15GmyMOKwc1q3KMgagL+RIlIa5T3WhYnK5MqroS0gUQiwfQejbBycDPIpBL8FnsX726PQU5+6aeOk3ZjmCEirdHWxfL57dAveV2C5xf0tnWxrM6ySMONbFsfP/p7w1AuRdiVBxi1IRoPn+aJXRapEcMMEWkNmVSCxf09AKBUoHnx+eL+HnxGD5XSo4ktAt9tj1rGcpy/8wRD15/C7Zfc4Ubah2GGiLRKH097BIxpBTuLkktOdhaGCBjT6qX7zBC1ql8bv03qgLq1jJCckY3BASdx4V6m2GWRGvACYCLSOn087eHrYYdT19JxJCIavTq3q9AOwFTzuNqYInhKB4zfcgaXUhQY+WMU1o/xRqdG1mKXRpUg6pmZFStWoE2bNjAzM4ONjQ0GDhyIK1eulBjz9OlTTJs2DfXq1YORkRGaNGmCgIAAkSomIk0hk0rQzsUS3tYC2rlYMshQudmaG2LX++3h08AKT/MK8M7W09gXd0/ssqgSRA0z4eHhmDp1KqKiohAaGoqCggL06tUL2dnZxWNmz56NkJAQ7NixA5cuXcLs2bMxffp07Nu3T8TKiYhIm5kbyrF1Qhv087KHslDAzJ1x2BhxQ+yyqIJEXWYKCQkp8fmWLVtgY2OD2NhYdOnSBQBw6tQpjBs3Dt26dQMAvPfee/jhhx8QExMDPz+/UnPm5eUhL+//r1JXKBQAAKVSCaVSqdb6X8yn7nk1BfvTfrreI/vTfmL2KAXw1RBPWJvIse3UbSw7eAn3H+dgXu/GkKrpTJ+u/wyrsj9V5pQIQlmPWRPHtWvX0KhRIyQkJMDT0xMAMGnSJMTGxmLv3r1wcHBAWFgYBgwYgEOHDqFTp06l5liyZAmWLl1a6nhgYCCMjY2rvAciItIuggAcvS/B/tsyAEArqyK87VoEPd4iI6qcnByMHj0amZmZMDc3f+VYjQkzgiDAz88Pjx8/RkRERPHx/Px8vPvuu9i+fTv09PQglUqxceNG+Pv7lzlPWWdmHB0dkZGR8dpvhqqUSiVCQ0Ph6+sLuVyu1rk1AfvTfrreI/vTfprU4964+5i/5yIKigR0aGiJb0e2gJlh5RYwNKm/qlCV/SkUClhbW5crzGjM3UzTpk1DfHw8IiMjSxxfu3YtoqKisH//fjg5OeH48eOYMmUK7O3t0bNnz1LzGBgYwMCg9IPj5HJ5lf0iVeXcmoD9aT9d75H9aT9N6HFYGyfYWhhj0o5YnLz+CP5bYrDlnTZqeYq6JvRXlaqiP1Xm04iTaNOnT8f+/ftx7Ngx1KtXr/j4s2fPsGDBAnz11Vfo378/vLy8MG3aNIwYMQJffvmliBUTEZEu6tK4Dna+1x5WJvq4eF+BIQEncePBU7HLotcQNcwIgoBp06YhODgYR48ehYuLS4nXX1y0K5WWLFMmk6GoqKg6SyUiohrCq14tBE3uACcrY9x59AxD159C3J0nYpdFryBqmJk6dSp27NiBwMBAmJmZITU1FampqXj27BkAwNzcHF27dsWcOXMQFhaG5ORkbN26Fdu3b8egQYPELJ2IiHSYs7UJgiZ3QLO6FniUnY9RP0bh2JV0scuilxA1zAQEBCAzMxPdunWDvb198ceuXbuKx+zcuRNt2rTB22+/DQ8PD6xcuRLLly/HpEmTRKyciIh0nbWpAXa+1x6dG1njmbIQE7fFYHfMHbHLojKIegFweW6ksrOzw5YtW6qhGiIiopJMDPSwaVwbfBwUj+Bz9zDnt3ikZ+VhSreGkEi467Sm0IgLgImIiDSVvp4U/xveHJO6NgQAfHH4Chbvv4jCIo3Y2YTAMENERPRaEokEH7/pjk/e8oBEAmw/dQvTAs8iV1kodmkEhhkiIqJym9DJBetGtYS+TIpDF1IxdvNpZD7TzUcVaBOGGSIiIhW85eWArRPawMxAD6eTH2H4+lNIzcwVu6wajWGGiIhIRR0aWmPX+z6wMTPAlbQsDP7+BK6lZ4ldVo3FMENERFQBHg7mCJrcAQ3qmOB+Zi6GBJxCzM1HYpdVIzHMEBERVZCjpTGCJnVAy/q1kPlMibc3RuPIxVSxy6pxGGaIiIgqobaJPgIntkcPdxvkFRRh0o5YBEbfFrusGoVhhoiIqJKM9GX4wd8bI1o7okgAFuxJwNehV8u1OSxVnqg7ABMREekKPZkUK4c0g62FIdb+lYQ1fyUhNTMH7fg3bZXjmRkiIiI1kUgk+MC3MZYN9IRUAuyKuYfNV6R4ls/N9aoSwwwREZGajWnvhO/f9oa+nhQXHksxbmsMHmfni12WzmKYISIiqgJ9PO2wbbw3jGQCzt3JxND1J3H3cY7YZekkhhkiIqIq0tqpNmZ6FsLO3ADXH2RjSMBJXEpRiF2WzmGYISIiqkL2xsCv77VDY1tTpCnyMHz9KZy6/lDssnQKwwwREVEVs7cwxO73O6CtsyWy8gowbvNpHIxPEbssncEwQ0REVA0sjOXY/p+26NPUDvmFRZj2y1lsPZEsdlk6gWGGiIiomhjKZfju7Vbwb+8EQQCWHEjEqpDL3FyvkhhmiIiIqpFMKsGnfk3xUa/GAICAsOv4cPd5KAuLRK5MezHMEBERVTOJRIJpbzTC6qFekEklCD57DxO3xSA7r0Ds0rQSwwwREZFIhrd2xIax3jCUSxF+9QFGbYhCxtM8scvSOgwzREREInrD3Ra/vNsetY3liL+biaEBJ3H7ITfXUwXDDBERkcha1q+NoMkdUK+2EW4+zMHggBNIuJspdllag2GGiIhIAzSoY4rgyR3gYW+OjKf5GPnjKUQkPRC7LK3AMENERKQhbMwNsev99ujoaoXs/EK8s+UM9p67J3ZZGo9hhoiISIOYGcqxZXxbDGjugIIiAbN2xeHH49e5F80rMMwQERFpGH09Kb4Z0QL/6eQCAPj8j8tYdvASiooYaMrCMENERKSBpFIJFr3lgYV9mwAANkUmY+auOOQVFIpcmeZhmCEiItJg73ZpgG9GtIBcJsGB8/fxzpYzyMpVil2WRmGYISIi0nADW9bF5vFtYKIvw8nrDzH8hyikK3LFLktjiBpmVqxYgTZt2sDMzAw2NjYYOHAgrly5UmKMRCIp8+OLL74QqWoiIqLq17lRHex63wfWpvq4lKLA4ICTuP7gqdhlaQRRw0x4eDimTp2KqKgohIaGoqCgAL169UJ2dnbxmJSUlBIfmzdvhkQiwZAhQ0SsnIiIqPp51rVA8OSOcLYyxt3HzzA04CTO3X4sdlmi0xPzzUNCQkp8vmXLFtjY2CA2NhZdunQBANjZ2ZUYs2/fPnTv3h0NGjSotjqJiIg0RX0rY/w2uQP+s/UMzt/NxOgN0fju7ZZ4w91W7NJEI2qY+bfMzOdbN1taWpb5elpaGg4ePIht27a9dI68vDzk5f3/Q7oUCgUAQKlUQqlU7wVTL+ZT97yagv1pP13vkf1pP13vsar6szCQYtt4b8zYdR7Hkx7i3e2x+GyAB4Z511Xr+7xOVf78VJlTImjILjyCIMDPzw+PHz9GREREmWNWr16NlStX4v79+zA0NCxzzJIlS7B06dJSxwMDA2FsbKzWmomIiMRUWATsvCHF6QfPrxrp51gI37oCJBKRC1ODnJwcjB49GpmZmTA3N3/lWI0JM1OnTsXBgwcRGRmJevXqlTnG3d0dvr6+WLdu3UvnKevMjKOjIzIyMl77zVCVUqlEaGgofH19IZfL1Tq3JmB/2k/Xe2R/2k/Xe6yO/gRBwFd/XsP648kAgLfbOmJRP3fIpFWfaKqyP4VCAWtr63KFGY1YZpo+fTr279+P48ePvzTIRERE4MqVK9i1a9cr5zIwMICBgUGp43K5vMp+kapybk3A/rSfrvfI/rSfrvdY1f193NcD9rWMseTARfx8+g4eZivxzcgWMJTLquw9/6kq+lNlPlHvZhIEAdOmTUNwcDCOHj0KFxeXl47dtGkTvL290bx582qskIiISDuM6+CM70a3gr5MipCLqRi76TQyc3TzWqR/EzXMTJ06FTt27EBgYCDMzMyQmpqK1NRUPHv2rMQ4hUKB3bt3Y+LEiSJVSkREpPn6NrPHtgltYWagh9M3H2HYDyeRkvns9V+o5UQNMwEBAcjMzES3bt1gb29f/PHvpaSdO3dCEASMGjVKpEqJiIi0g09DK/w6yQe25ga4mvYUg78/iatpWWKXVaVEX2Yq62P8+PElxr333nvIycmBhYWFOIUSERFpkSb25gie0hEN65ggJTMXQwNO4szNR2KXVWX4bCYiIiIdVLeWEX6b1AGt6teCIrcAYzZGI+RCqthlVQmGGSIiIh1V20QfP09sj55NbJFXUIQpP8diR9QtsctSO4YZIiIiHWakL8P6Ma0wqq0jigTgv3sv4KsjV6Ah28ypBcMMERGRjtOTSfH5oGaY1bMRAGDt0Wv4OCgBBYVFIlemHgwzRERENYBEIsGsno3x+aBmkEqAXTF38P5PsXiWXyh2aZXGMENERFSDjG5XH+vHeMNAT4q/Lqdj9MYoPMrOF7usSmGYISIiqmF6NbVD4LvtYGEkx7nbTzB0/UnceZQjdlkVxjBDRERUA3k7WSJosg8cLAxx40E2BgecROJ9hdhlVQjDDBERUQ3lamOG4Ckd4W5nhgdZeRjxwymcvJ4hdlkqY5ghIiKqwewsDLHrfR+0c7FEVl4Bxm8+gwPn74tdlkoYZoiIiGo4CyM5tk1oi77N7JBfWITpv5zD5shkscsqN4YZIiIigqFchnWjWmGcjxMA4NPfE7Hi0CUUFWn+5noMM0RERAQAkEklWDKgKeb2cQMA/BB+Ax/uPo/8As3eXI9hhoiIiIpJJBJM6eaKL4Z6QSaVYM+5e/jPtjN4mlcgdmkvxTBDREREpQxr7YiN41rDSC5DRFIGRv0YhQdZeWKXVSaGGSIiIipTdzcb/PJee1ia6CPhXiaGrj+JWw+zxS6rFIYZIiIieqkWjrUQNLkDHC2NcOthDgZ/fxLxd5+gsEhAdPIjxGZIEJ38CIUiXiisJ9o7ExERkVZwsTZB0OQOeGfLGVy8r8DQ9adgoq+Hxzn5AGTYnhQDewtDLO7vgT6e9tVeH8/MEBER0WvZmD3fXM/dzgz5BUV/B5n/l5qZi8k7ziLkQkq118YwQ0REROViJJfhSY6yzNdeLDItPZBY7UtODDNERERULqeTHyFVkfvS1wUAKZm5OJ38qPqKAsMMERERlVN61suDTEXGqQvDDBEREZWLjZmhWsepC8MMERERlUtbF0vYWxhC8pLXJQDsLQzR1sWyOstimCEiIqLykUklWNzfAwBKBZoXny/u7wGZ9GVxp2owzBAREVG59fG0R8CYVrCzKLmUZGdhiIAxrUTZZ4ab5hEREZFK+njaw9fDDqeupeNIRDR6dW4HH1ebaj8j8wLDDBEREalMJpWgnYslHl4S0M7FUrQgA3CZiYiIiLQcwwwRERFpNYYZIiIi0mqihpkVK1agTZs2MDMzg42NDQYOHIgrV66UGnfp0iUMGDAAFhYWMDMzQ/v27XH79m0RKiYiIiJNI2qYCQ8Px9SpUxEVFYXQ0FAUFBSgV69eyM7OLh5z/fp1dOrUCe7u7ggLC8P58+exaNEiGBpW7+6CREREpJlEvZspJCSkxOdbtmyBjY0NYmNj0aVLFwDAwoUL0bdvX6xevbp4XIMGDV46Z15eHvLy8oo/VygUAAClUgmlsuwnfVbUi/nUPa+mYH/aT9d7ZH/aT9d7ZH+Vn7s8JIIgVO9zul/h2rVraNSoERISEuDp6YmioiJYWFhg7ty5iIyMxLlz5+Di4oL58+dj4MCBZc6xZMkSLF26tNTxwMBAGBsbV3EHREREpA45OTkYPXo0MjMzYW5u/sqxGhNmBEGAn58fHj9+jIiICABAamoq7O3tYWxsjGXLlqF79+4ICQnBggULcOzYMXTt2rXUPGWdmXF0dERGRsZrvxmqUiqVCA0Nha+vL+RyuVrn1gTsT/vpeo/sT/vpeo/sr+IUCgWsra3LFWY0ZtO8adOmIT4+HpGRkcXHioqKAAB+fn6YPXs2AKBFixY4efIk1q9fX2aYMTAwgIGBQanjcrm8yn6RqnJuTcD+tJ+u98j+tJ+u98j+KjZneWlEmJk+fTr279+P48ePo169esXHra2toaenBw8PjxLjmzRpUiL0vMqLE08vrp1RJ6VSiZycHCgUCp38JWV/2k/Xe2R/2k/Xe2R/Fffi7+3yLCCJGmYEQcD06dOxZ88ehIWFwcXFpcTr+vr6aNOmTanbta9evQonJ6dyvUdWVhYAwNHRUT1FExERUbXJysqChYXFK8eIGmamTp2KwMBA7Nu3D2ZmZkhNTQUAWFhYwMjICAAwZ84cjBgxAl26dCm+ZubAgQMICwsr13s4ODjgzp07MDMzg0Si3udGvLge586dO2q/HkcTsD/tp+s9sj/tp+s9sr+KEwQBWVlZcHBweO1YUS8Aflm42LJlC8aPH1/8+ebNm7FixQrcvXsXbm5uWLp0Kfz8/KqpypdTKBSwsLAo18VJ2oj9aT9d75H9aT9d75H9VQ/Rl5nKY8KECZgwYUIVV0NERETaiM9mIiIiIq3GMFMJBgYGWLx4cZm3gusC9qf9dL1H9qf9dL1H9lc9NGbTPCIiIqKK4JkZIiIi0moMM0RERKTVGGaIiIhIqzHMEBERkVar0WHm+++/h4uLCwwNDeHt7V38tO6XCQ8Ph7e3NwwNDdGgQQOsX7++1JigoCB4eHjAwMAAHh4e2LNnT4nXjx8/jv79+8PBwQESiQR79+5VZ0sliNHfihUr0KZNG5iZmcHGxgYDBw4s9TgKdRGjv4CAAHh5ecHc3Bzm5ubw8fHBoUOH1NrXP4nR4z+tWLECEokEs2bNqmwrZRKjvyVLlkAikZT4sLOzU2tfL4j187t37x7GjBkDKysrGBsbo0WLFoiNjVVbX/8kRo/Ozs6lfoYSiQRTp05Va2+AOP0VFBTgv//9L1xcXGBkZIQGDRrg008/LX74sjqJ0V9WVhZmzZoFJycnGBkZoUOHDjhz5kzlGhFqqJ07dwpyuVzYsGGDkJiYKMycOVMwMTERbt26Veb4GzduCMbGxsLMmTOFxMREYcOGDYJcLhd+++234jEnT54UZDKZ8PnnnwuXLl0SPv/8c0FPT0+IiooqHvPHH38ICxcuFIKCggQAwp49e3Sqv969ewtbtmwRLly4IMTFxQn9+vUT6tevLzx9+lQn+tu/f79w8OBB4cqVK8KVK1eEBQsWCHK5XLhw4YJa+xOzxxdOnz4tODs7C15eXsLMmTN1pr/FixcLTZs2FVJSUoo/0tPTdaa/R48eCU5OTsL48eOF6OhoITk5Wfjzzz+Fa9eu6UyP6enpJX5+oaGhAgDh2LFjOtHfsmXLBCsrK+H3338XkpOThd27dwumpqbCN998oxP9DR8+XPDw8BDCw8OFpKQkYfHixYK5ublw9+7dCvdSY8NM27ZthUmTJpU45u7uLnz88cdljp87d67g7u5e4tj7778vtG/fvvjz4cOHC3369Ckxpnfv3sLIkSPLnLMqw4wm9CcIz//QASCEh4er2sIraUp/giAItWvXFjZu3KhK+eUiZo9ZWVlCo0aNhNDQUKFr165VEmbE6m/x4sVC8+bNK1n964nV37x584ROnTpVtvxy0ZT/D2fOnCk0bNhQKCoqUrWFVxKrv379+gkTJkwoMWbw4MHCmDFjKtTHy4jRX05OjiCTyYTff/+9xJjmzZsLCxcurHAvNXKZKT8/H7GxsejVq1eJ47169cLJkyfL/JpTp06VGt+7d2/ExMRAqVS+cszL5qwqmtRfZmYmAMDS0lLlPl5GU/orLCzEzp07kZ2dDR8fn4q2Uyaxe5w6dSr69euHnj17VraVMondX1JSEhwcHODi4oKRI0fixo0blW2pBDH7279/P1q3bo1hw4bBxsYGLVu2xIYNG9TRVgli/wz/WceOHTswYcIEtT5MWMz+OnXqhL/++gtXr14FAJw/fx6RkZHo27dvpft6Qaz+CgoKUFhYCENDwxJjjIyMEBkZWeF+amSYycjIQGFhIWxtbUsct7W1LX5y97+lpqaWOb6goAAZGRmvHPOyOauKpvQnCAI++OADdOrUCZ6enhVtpxSx+0tISICpqSkMDAwwadIk7NmzBx4eHpVtqwQxe9y5cyfOnj2LFStWqKOVMonZX7t27bB9+3YcPnwYGzZsQGpqKjp06ICHDx+qozUA4vZ348YNBAQEoFGjRjh8+DAmTZqEGTNmYPv27eporZjY/x++sHfvXjx58qTEw4nVQcz+5s2bh1GjRsHd3R1yuRwtW7bErFmzMGrUKHW0BkC8/szMzODj44PPPvsM9+/fR2FhIXbs2IHo6GikpKRUuB9RHzQptn+neEEQXpnsyxr/7+OqzlmVxO5v2rRpiI+Pr1TafhWx+nNzc0NcXByePHmCoKAgjBs3DuHh4WoPNOWt53Xj/338VXPeuXMHM2fOxJEjR0r9y6kqiPEzfPPNN4v/u1mzZvDx8UHDhg2xbds2fPDBB6o38Qpi9FdUVITWrVvj888/BwC0bNkSFy9eREBAAMaOHVuxRl5B7D9nNm3ahDfffBMODg4q1V1eYvS3a9cu7NixA4GBgWjatCni4uIwa9YsODg4YNy4cRXupbz1VnV/P/30EyZMmIC6detCJpOhVatWGD16NM6ePVvhPmpkmLG2toZMJiuVPtPT00slyhfs7OzKHK+npwcrK6tXjnnZnFVFE/qbPn069u/fj+PHj6NevXqVaacUsfvT19eHq6srAKB169Y4c+YM1qxZgx9++KFSff2TWD3GxsYiPT0d3t7exa8XFhbi+PHj+Pbbb5GXlweZTKa1/ZXFxMQEzZo1Q1JSUkVaKZOY/dnb25cK1k2aNEFQUFCF+ymLJvwMb926hT///BPBwcGVaaVMYvY3Z84cfPzxxxg5ciSA56H71q1bWLFihdrCjJj9NWzYEOHh4cjOzoZCoYC9vT1GjBgBFxeXCvdTI5eZ9PX14e3tjdDQ0BLHQ0ND0aFDhzK/xsfHp9T4I0eOoHXr1pDL5a8c87I5q4qY/QmCgGnTpiE4OBhHjx6t1C/ny2jaz08QBOTl5anaxiuJ1WOPHj2QkJCAuLi44o/WrVvj7bffRlxcnFqCjJj9lSUvLw+XLl2Cvb19RVopk5j9dezYsdR2CFevXoWTk1OF+ymLJvwMt2zZAhsbG/Tr168yrZRJzP5ycnIglZb861kmk6n11mxN+PmZmJjA3t4ejx8/xuHDh+Hn51fxhip86bCWe3FL2qZNm4TExERh1qxZgomJiXDz5k1BEATh448/Fvz9/YvHv7glbfbs2UJiYqKwadOmUreknThxQpDJZMLKlSuFS5cuCStXrix1S1pWVpZw7tw54dy5cwIA4auvvhLOnTv30lvhtK2/yZMnCxYWFkJYWFiJWydzcnJ0or/58+cLx48fF5KTk4X4+HhhwYIFglQqFY4cOaLW/sTs8d+q6m4msfr78MMPhbCwMOHGjRtCVFSU8NZbbwlmZmbF76vt/Z0+fVrQ09MTli9fLiQlJQk///yzYGxsLOzYsUOt/YnZoyAIQmFhoVC/fn1h3rx5au9L7P7GjRsn1K1bt/jW7ODgYMHa2lqYO3euTvQXEhIiHDp0SLhx44Zw5MgRoXnz5kLbtm2F/Pz8CvdSY8OMIAjCd999Jzg5OQn6+vpCq1atStw+PG7cOKFr164lxoeFhQktW7YU9PX1BWdnZyEgIKDUnLt37xbc3NwEuVwuuLu7C0FBQSVeP3bsmACg1Me4ceN0or+yegMgbNmyRSf6mzBhQvF71qlTR+jRo0eVBJkXxOjx36oqzAiCOP2NGDFCsLe3F+RyueDg4CAMHjxYuHjxos70JwiCcODAAcHT01MwMDAQ3N3dhR9//FHtvb0gVo+HDx8WAAhXrlxRe0//JEZ/CoVCmDlzplC/fn3B0NBQaNCggbBw4UIhLy9PJ/rbtWuX0KBBA0FfX1+ws7MTpk6dKjx58qRSfUgE4e+rd4iIiIi0UI28ZoaIiIh0B8MMERERaTWGGSIiItJqDDNERESk1RhmiIiISKsxzBAREZFWY5ghIiIircYwQ0RERFqNYYaIqsTWrVtRq1Ytlb5m/PjxGDhwYJXUQ0S6i2GGqIZbv349zMzMUFBQUHzs6dOnkMvl6Ny5c4mxERERkEgkuHr16mvnHTFiRLnGqcrZ2RnffPNNucZJJBJIJBIYGRnB2dkZw4cPx9GjR9VeExGJi2GGqIbr3r07nj59ipiYmOJjERERsLOzw5kzZ5CTk1N8PCwsDA4ODmjcuPFr5zUyMoKNjU2V1Fxen376KVJSUnDlyhVs374dtWrVQs+ePbF8+XJR6yIi9WKYIarh3Nzc4ODggLCwsOJjYWFh8PPzQ8OGDXHy5MkSx7t37w4AyM/Px9y5c1G3bl2YmJigXbt2JeYoa5lp2bJlsLGxgZmZGSZOnIiPP/4YLVq0KFXTl19+CXt7e1hZWWHq1KlQKpUAgG7duuHWrVuYPXt28VmXVzEzM4OdnR3q16+PLl264Mcff8SiRYvwySef4MqVK8XjEhMT0bdvX5iamsLW1hb+/v7IyMgofr2oqAirVq2Cq6srDAwMUL9+/RKBaN68eWjcuDGMjY3RoEEDLFq0qLjmmzdvQiqVlgiLALBu3To4OTmBj8cjqjyGGSJCt27dcOzYseLPjx07hm7duqFr167Fx/Pz83Hq1KniMPPOO+/gxIkT2LlzJ+Lj4zFs2DD06dMHSUlJZb7Hzz//jOXLl2PVqlWIjY1F/fr1ERAQUGrcsWPHcP36dRw7dgzbtm3D1q1bsXXrVgBAcHAw6tWrV3zGJSUlReVeZ86cCUEQsG/fPgBASkoKunbtihYtWiAmJgYhISFIS0vD8OHDi79m/vz5WLVqFRYtWoTExEQEBgbC1ta2+HUzMzNs3boViYmJWLNmDTZs2ICvv/4awPPlrp49e2LLli0l6tiyZQvGjx//2kBGROVQqWduE5FO+PHHHwUTExNBqVQKCoVC0NPTE9LS0oSdO3cKHTp0EARBEMLDwwUAwvXr14Vr164JEolEuHfvXol5evToIcyfP18QBEHYsmWLYGFhUfxau3bthKlTp5YY37FjR6F58+bFn48bN05wcnISCgoKio8NGzZMGDFiRPHnTk5Owtdff/3anl41ztbWVpg8ebIgCIKwaNEioVevXiVev3PnjgBAuHLliqBQKAQDAwNhw4YNr33PF1avXi14e3sXf75r1y6hdu3aQm5uriAIghAXFydIJBIhOTm53HMS0cvxzAwRoXv37sjOzsaZM2cQERGBxo0bw8bGBl27dsWZM2eQnZ2NsLAw1K9fHw0aNMDZs2chCAIaN24MU1PT4o/w8HBcv369zPe4cuUK2rZtW+LYvz8HgKZNm0ImkxV/bm9vj/T0dLX2KwhC8RmR2NhYHDt2rEQf7u7uAIDr16/j0qVLyMvLQ48ePV4632+//YZOnTrBzs4OpqamWLRoEW7fvl38+sCBA6Gnp4c9e/YAADZv3ozu3bvD2dlZrX0R1VR6YhdAROJzdXVFvXr1cOzYMTx+/Bhdu3YFANjZ2cHFxQUnTpzAsWPH8MYbbwB4fg2JTCZDbGxsieABAKampi99n38vqQhlXC8il8tLfU1RUVGF+irLw4cP8eDBA7i4uAB43kv//v2xatWqUmPt7e1x48aNV84XFRWFkSNHYunSpejduzcsLCywc+dO/O9//yseo6+vD39/f2zZsgWDBw9GYGBgue7IIqLyYZghIgDPz86EhYXh8ePHmDNnTvHxrl274vDhw4iKisI777wDAGjZsiUKCwuRnp5e6vbtl3Fzc8Pp06fh7+9ffOzfF8WWh76+PgoLC1X+uhfWrFkDqVRavJ9Nq1atEBQUBGdnZ+jplf4jsVGjRjAyMsJff/2FiRMnlnr9xIkTcHJywsKFC4uP3bp1q9S4iRMnwtPTE99//z2USiUGDx5c4R6IqCQuMxERgOdhJjIyEnFxccVnZoDnYWbDhg3Izc0tvvi3cePGePvttzF27FgEBwcjOTkZZ86cwapVq/DHH3+UOf/06dOxadMmbNu2DUlJSVi2bBni4+NVvgDW2dkZx48fx71790rccVSWrKwspKam4s6dOzh+/Djee+89LFu2DMuXL4erqysAYOrUqXj06BFGjRqF06dP48aNGzhy5AgmTJiAwsJCGBoaYt68eZg7dy62b9+O69evIyoqCps2bQLw/KzW7du3sXPnTly/fh1r164tXk76pyZNmqB9+/aYN28eRo0aBSMjI5X6JqJXEPmaHSLSEMnJyQIAwd3dvcTxFxfDNmzYsMTx/Px84ZNPPhGcnZ0FuVwu2NnZCYMGDRLi4+MFQSh9AbAgCMKnn34qWFtbC6ampsKECROEGTNmCO3bty9+fdy4cYKfn1+Jr5k5c6bQtWvX4s9PnToleHl5CQYGBsKr/ghzcnISAAgABH19faF+/frC8OHDhaNHj5Yae/XqVWHQoEFCrVq1BCMjI8Hd3V2YNWuWUFRUJAiCIBQWFgrLli0TnJycBLlcLtSvX1/4/PPPi79+zpw5gpWVlWBqaiqMGDFC+Prrr0v1LgiCsGnTJgGAcPr06ZfWTUSqkwgCNzkgInH4+vrCzs4OP/30k9ilVIvly5dj586dSEhIELsUIp3Ca2aIqFrk5ORg/fr16N27N2QyGX755Rf8+eefCA0NFbu0Kvf06VNcunQJ69atw2effSZ2OUQ6h9fMEFG1kEgk+OOPP9C5c2d4e3vjwIEDCAoKQs+ePcUurcpNmzYNnTp1QteuXTFhwgSxyyHSOVxmIiIiIq3GMzNERESk1RhmiIiISKsxzBAREZFWY5ghIiIircYwQ0RERFqNYYaIiIi0GsMMERERaTWGGSIiItJq/wc/e7a9AooknQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight_decay_list = [1e-3, 3e-3, 5e-3, 7e-3, 9e-3]\n",
    "l2_norm_results = [] # store l2 norm for each weight_decay\n",
    "\n",
    "# Training loop for different weight_decay values\n",
    "for wd in weight_decay_list:\n",
    "    print(f'Training weight decay: {wd}')\n",
    "    model = FNN()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.AdamW(get_param_groups(model, weight_decay=wd), lr=1e-3)\n",
    "    train(model, train_loader, criterion, optimizer, num_epochs=500)\n",
    "    norm_value = get_all_weights_l2norm(model)\n",
    "    l2_norm_results.append(norm_value)\n",
    "\n",
    "# plot weight_decay and l2 norm \n",
    "plt.plot(weight_decay_list, l2_norm_results, marker='o')\n",
    "plt.xlabel('Weight Decay')\n",
    "plt.ylabel('L2 Norm of Weights')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad6e345",
   "metadata": {},
   "source": [
    "## 2 - Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7943ec",
   "metadata": {},
   "source": [
    "We can implement dropout by modifying network structure. In the following codes, we define `FNN_dropout` a network with dropout layer.\n",
    "\n",
    "In the `__init__` method, `self.dropout1 = nn.Dropout(p=0.5)` defines a dropout layer with dropout probability of 0.5, it would randomly zeroes some elements of the input with probability $p=0.5$ during training mode.\n",
    "\n",
    "In the `forward` method, `x = self.dropout1(x)` applies the dropout operator to the output of first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4656ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN_dropout(nn.Module):\n",
    "    \"\"\"\n",
    "    A fully connected neural network with dropout.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(FNN_dropout, self).__init__()\n",
    "        self.fc1 = nn.Linear(24, 64)\n",
    "        self.dropout1 = nn.Dropout(p=0.5) # define dropout layer with 50% probability\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.dropout2 = nn.Dropout(p=0.3) # define dropout layer with 30% probability\n",
    "        self.fc3 = nn.Linear(32, 8)\n",
    "        self.dropout3 = nn.Dropout(p=0.1) # define dropout layer with 10% probability\n",
    "        self.fc4 = nn.Linear(8, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x) # apply dropout\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x) # apply dropout\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout3(x) # apply dropout\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef00feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout = FNN_dropout()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_dropout.parameters(), lr=3e-4)\n",
    "train(model_dropout, train_loader, criterion, optimizer, num_epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b450c97",
   "metadata": {},
   "source": [
    "## 3 - Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637892a4",
   "metadata": {},
   "source": [
    "Early Stopping technique monitors a model's metric (e.g. loss, auc) on a validation set and stops training when the metric starts to increase. The implementation of early stopping is easy, we start from defining a `EarlyStopping` class. This `EarlyStopping` class is a utility used for detect improment, save the best model and stop training if no improvement.\n",
    "\n",
    "How it works:\n",
    "- `__call__` method:\n",
    "  1. On first call, records the initial validation loss and saves the model\n",
    "  2. When improvement is detected (metric decreases by at least `delta`): Updates `best_metric` -> Saves the model -> Resets the patience counter\n",
    "  3. When no improvement: Increments the `counter` -> Triggers stop if `patience` is exceeded\n",
    "- `save_checkpoint` method:\n",
    "  1. Saves the model's state dictionary to the specified path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bad27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    '''\n",
    "    Early stops training if metric doesn't imporve after patience (expect lower metric are better)\n",
    "    '''\n",
    "    def __init__(self, patience=50, delta=0, path='checkpoint.pt', verbose=False):\n",
    "        self.patience = patience # number of epochs to wait since no improvement\n",
    "        self.delta = delta # score reduction required to detect siginificant improvement\n",
    "        self.counter = 0 # counter of patience\n",
    "        self.stop = False # flag for stop training\n",
    "        self.best_metric = None\n",
    "        # self.verbose = verbose\n",
    "        self.path = path # path to save the check point\n",
    "    \n",
    "    def __call__(self, valid_metric, model):\n",
    "        if self.best_metric is None:\n",
    "            # first call\n",
    "            self.best_metric = valid_metric\n",
    "            self.save_checkpoint(valid_metric, model)\n",
    "        elif valid_metric < self.best_metric - self.delta:\n",
    "            # significant improvement detect\n",
    "            self.best_metric = valid_metric # update best loss\n",
    "            self.save_checkpoint(valid_metric, model) # save the model\n",
    "            self.counter = 0 # resets the patience counter\n",
    "        else:\n",
    "            # no significant improvement\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop = True\n",
    "\n",
    "    def save_checkpoint(self, valid_metric, model):\n",
    "        '''save models when metric decreases'''\n",
    "        # if self.verbose:\n",
    "        #     print(f'loss improvement: {valid_metric:.6f}. Saving model.')\n",
    "        torch.save(model.state_dict(), self.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820c342f",
   "metadata": {},
   "source": [
    "We can implement early stopping by modifing previous `train` function in the following way:\n",
    "1. instanciate a `EarlyStopping` class\n",
    "2. loop until `num_epochs` or until early stopping triggers\n",
    "   1. train the model (same as last chapter)\n",
    "   2. get validation loss and probability using `test()` function\n",
    "   3. call `early_stopping` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4e7274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, valid_loader, criterion, optimizer, num_epochs, early_stop='loss'):\n",
    "    '''\n",
    "    train the model and early stopping on the validation loss\n",
    "    params:\n",
    "        model: the neural network model to train\n",
    "        train_loader: DataLoader, training data;\n",
    "        valid_loader: DataLoader, validation data;\n",
    "        criterion: loss function;\n",
    "        optimizer: optimization algorithm\n",
    "        num_epochs: int, number of epochs\n",
    "        early_stop: early stopping strategy:\n",
    "                    - False: No early stopping\n",
    "                    - 'loss': monitor validation loss\n",
    "                    - 'auprc': monitor validation auprc\n",
    "    return:\n",
    "        model: trained model (best version if early stopping used)\n",
    "        train_losses: list, training losses per epoch\n",
    "        valid_losses: list, validation losses per epoch\n",
    "    '''\n",
    "    train_losses, valid_losses = [], [] # used to store loss of all epochs\n",
    "    early_stopping = EarlyStopping() # initialize an EarlyStopping object\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # train the model\n",
    "        model.train()\n",
    "        acc_train_loss = 0 # used to store training loss of all batches\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad() # clear previous gradients\n",
    "            output = model(data) # forward propagation\n",
    "            loss = criterion(output.squeeze(1), target) # calculate average batch loss\n",
    "            loss.backward() # backpropagation\n",
    "            optimizer.step() # update parameters\n",
    "            acc_train_loss += loss.item() * data.size(0) # accumulate loss\n",
    "        train_loss = acc_train_loss / len(train_loader.dataset) # calculate average epoch loss\n",
    "        train_losses.append(train_loss)\n",
    "        if (epoch + 1) % 50 == 0: # print loss each 50 epochs\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # validate the model\n",
    "        valid_loss, valid_probs = test(model, valid_loader, criterion)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_auprc = average_precision_score(y_valid_array, valid_probs)\n",
    "\n",
    "        # early stopping\n",
    "        if early_stop:\n",
    "            if early_stop == 'loss':\n",
    "                early_stopping(valid_loss, model)\n",
    "            elif early_stop == 'auprc':\n",
    "                early_stopping(-valid_auprc, model)\n",
    "            if early_stopping.stop:\n",
    "                print(f'early stopping in epoch {epoch}.')\n",
    "                break\n",
    "            model.load_state_dict(torch.load('checkpoint.pt', weights_only=True)) # load the best model\n",
    "    return model, train_losses, valid_losses\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d7d92",
   "metadata": {},
   "source": [
    "In the following codes, we train the model with early stopping. The training procedures stops at epoch 142, and epoch 92 has the minimum validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30271b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNN()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "model, train_losses, valid_losses = train_and_validate(model, train_loader, valid_loader, criterion, optimizer, 500, early_stop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c48748",
   "metadata": {},
   "source": [
    "We can plot the training loss and validation loss of all epochs. The training losses keep decreasing, but the validation loss begin increasing after epoch 92."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c526133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_losses)),train_losses, label='Training Loss')\n",
    "plt.plot(range(len(valid_losses)),valid_losses,label='Validation Loss')\n",
    "plt.axvline(valid_losses.index(min(valid_losses)), linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.xlim(0, len(train_losses))\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b0c001",
   "metadata": {},
   "source": [
    "## 4 - Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5ea1e3",
   "metadata": {},
   "source": [
    "Batch normalization normalizes the inputs to each layer by re-centering them around zero and scaling them to a standard size. We can implement batch normalization by modifying the network structure.\n",
    "\n",
    "In the `__init__` method, `self.bn1 = nn.BatchNorm1d(64)` defines a batch normalization over a 2D input with 64 features.\n",
    "\n",
    "In the `forward` method, `x = torch.relu(self.bn1(self.fc1(x)))` firstly do the linear transformation, then apply batch normalization, and then do relu activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f30fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN_bn(nn.Module):\n",
    "    \"\"\"\n",
    "    A fully connnected neural network with batch normalization\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(FNN_bn, self).__init__()\n",
    "        self.fc1 = nn.Linear(24, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64) # defines batch normalization over a 2D input with 64 features\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.bn2 = nn.BatchNorm1d(32) # defines batch normalization over a 2D input with 32 features\n",
    "        self.fc3 = nn.Linear(32, 8)\n",
    "        self.bn3 = nn.BatchNorm1d(8) # defines batch normalization over a 2D input with 8 features\n",
    "        self.fc4 = nn.Linear(8, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn = FNN_bn()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_bn.parameters(), lr=3e-4)\n",
    "train(model_bn, train_loader, criterion, optimizer, num_epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e01c181",
   "metadata": {},
   "source": [
    "## 5 - Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a819173",
   "metadata": {},
   "source": [
    "There are many third-party libraries that can help you automatically tunning hyperparameters. Here, we tune by hands.\n",
    "\n",
    "Firstly, we define a parameters grid containing all the possible values of hyperparameters. Since `hidden_layers` and `dropout_rates` must have the same length, after expanding the grid, we need to filter out the combinations with different `hidden_layers` and `dropout_rates` lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00655702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the values of hyperparameters to be trained\n",
    "param_grid = {\n",
    "    'batch_size': [256, 128, 64],\n",
    "    'hidden_layers': [[64, 32, 16], [32, 8]], # number of neurons in each hidden layers\n",
    "    'dropout_rates': [[0, 0, 0], [0, 0]],\n",
    "    'batch_norm': [True, False],\n",
    "    'criterion': ['BCE'],\n",
    "    'optimizer': ['Adam'],\n",
    "    'lr': [3e-3, 1e-3, 3e-4],\n",
    "    'weight_decay': [0, 1e-4, 3e-4],\n",
    "    'num_epochs': [100, 300, 500],\n",
    "    'early_stop': ['auprc', False],\n",
    "}\n",
    "\n",
    "# expand the grid to combinations\n",
    "keys, values = zip(*param_grid.items())\n",
    "all_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "# filter out combination that hidden_layers and dropout_rates have different lengths\n",
    "all_combinations = [\n",
    "    combo for combo in all_combinations \n",
    "    if len(combo['hidden_layers']) == len(combo['dropout_rates'])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427712f7",
   "metadata": {},
   "source": [
    "Secondly, we build a flexible neural network `Net`, its architecture depends on the input parameters `input_dim`, `hidden_layers`, `dropout_rates` and `use_batchnorm`.\n",
    "\n",
    "`__init__` method:\n",
    "1. Iterates through each specified hidden layer size\n",
    "2. For each layer, adds:\n",
    "    1. Linear transformation (nn.Linear)\n",
    "    2. Batch normalization (if enabled)\n",
    "    3. ReLU activation\n",
    "    4. Dropout (if `dropout_rates > 0`)\n",
    "3. Final linear layer reduces to 1 output neuron\n",
    "4. Sigmoid activation for binary classification\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layers, dropout_rates, use_batchnorm=False):\n",
    "        '''\n",
    "        params:\n",
    "            input_dim: int, dimension of input features;\n",
    "            hidden_layers: list, number of neurons for each hidden layers;\n",
    "            dropout_rates: list, same length as hidden_layers, dropout probability for each hidden layer;\n",
    "            use_batchnorm: bool, use batch normalization in each layer.\n",
    "        '''\n",
    "        super(Net, self).__init__()\n",
    "        layers = [] # store all the layers\n",
    "        prev_dim = input_dim\n",
    "        for i, hidden_dim in enumerate(hidden_layers): # loop over hidden layers\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim)) # add linear layer\n",
    "            if use_batchnorm: # if enable batch normalization\n",
    "                layers.append(nn.BatchNorm1d(hidden_dim)) # add batch normalization layer\n",
    "            layers.append(nn.ReLU()) # add ReLu activation\n",
    "            if dropout_rates[i] > 0: # if enable dropout\n",
    "                layers.append(nn.Dropout(dropout_rates[i])) # add dropout layer\n",
    "            prev_dim = hidden_dim \n",
    "        layers.append(nn.Linear(prev_dim, 1)) # add linear layer\n",
    "        layers.append(nn.Sigmoid()) # sigmoid transformation to output probability\n",
    "        self.network = nn.Sequential(*layers) # combining layers into a container\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x) # pass input sequentially through all the layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8aa4d4",
   "metadata": {},
   "source": [
    "Thirdly, we define a `tune()` function. This function would loop over all the hyperparameter combinations and calculate the validation loss, then write the information to `output_file`.\n",
    "\n",
    "How it works:\n",
    "1. prepare train_loader and valid_loader based on `batch_size`;\n",
    "2. build network based on `hidden_layers`, `dropout_rates` and `batch_norm`;\n",
    "3. prepare loss function and optimizer based on;\n",
    "4. train the model using `train_and_validate`\n",
    "5. save information (hyperparaters and validation loss) to `output_file`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dc5649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(combinations, output_file='output.txt'):\n",
    "    '''\n",
    "    loop over combinations and calculate validation loss \n",
    "    params:\n",
    "        combindations: list, each element is a dict containing hyperparameter's name and value;\n",
    "        output_file: file path to save the output.\n",
    "    return:\n",
    "        None\n",
    "    '''\n",
    "    with open(output_file, 'w') as f: # clean output_file\n",
    "        pass\n",
    "\n",
    "    for config in combinations:\n",
    "        print(f'config: {config}')\n",
    "    \n",
    "        # prepare data\n",
    "        train_loader = prepare_loader(X_train_array, y_train_array, batch_size=config['batch_size'], shuffle=True)\n",
    "        valid_loader = prepare_loader(X_valid_array, y_valid_array, batch_size=config['batch_size'], shuffle=False)\n",
    "        \n",
    "        # build model\n",
    "        model = Net(\n",
    "            input_dim=next(iter(train_loader))[0].shape[1],\n",
    "            hidden_layers=config['hidden_layers'],\n",
    "            dropout_rates=config['dropout_rates'],\n",
    "            use_batchnorm=config['batch_norm']\n",
    "        )\n",
    "        \n",
    "        # loss\n",
    "        if config['criterion'] == 'BCE':\n",
    "            criterion = nn.BCELoss()\n",
    "        else:\n",
    "            raise ValueError('Unknown criterion')\n",
    "        \n",
    "        # optimizer\n",
    "        if config['optimizer'] == 'Adam':\n",
    "            optimizer = torch.optim.Adam(get_param_groups(model, weight_decay=config['weight_decay']), lr=config['lr'])\n",
    "        else:\n",
    "            raise ValueError(\"Unknown optimizer\")\n",
    "        \n",
    "        # train & validate\n",
    "        model, _, _ = train_and_validate(model, train_loader, valid_loader, criterion, optimizer, config['num_epochs'], config['early_stop'])\n",
    "        \n",
    "        # save results\n",
    "        valid_loss, pred_probs = test(model, valid_loader, criterion)\n",
    "        config['valid_loss'] = valid_loss\n",
    "        valid_auprc = average_precision_score(y_valid_array, pred_probs)\n",
    "        result = {**config, \"valid_auprc\": valid_auprc}\n",
    "\n",
    "        with open(output_file, 'a') as f:\n",
    "            f.write(json.dumps(result) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce11a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune(all_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93f7637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
