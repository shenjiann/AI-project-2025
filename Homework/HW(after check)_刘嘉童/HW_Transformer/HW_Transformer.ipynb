{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a015332-d611-43e7-99ab-9efb7b6c5daa",
   "metadata": {},
   "source": [
    "# Homework X:  Transformer Structure Practical Training Project\n",
    "\n",
    "Welcome to the course **AI and Deep learning**!\n",
    "\n",
    "We have started learning about RNN. In this assignment, we will work on a hands-on training project on transformer structure. In this project, we will perform sentiment analysis on a financial text dataset to determine the sentiment type of short texts. Hope you enjoy this homework!   \n",
    "\n",
    "**Learning Goal**: In this homework,you will achieve the following:\n",
    " * Learn more about the structure of the transformer through the code.\n",
    " * Learn how to perform sentiment analysis with Transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1fa05b-bfc3-4fa6-bcc5-ef258c510a37",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [1 - Packages](#1)\n",
    "* [2 - Dataset](#2)\n",
    "* [3 - Transformer structure](#3)\n",
    "* [4 - Training and Saving Model](#4)\n",
    "* [5 - Play by Yourself!](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc46c98-dee2-42f5-9c3e-70b2272da013",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1- Packages\n",
    "\n",
    "In order to finish a task, we need commands from certain **Python** packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "790f22ed-9db0-43de-a47a-4e2709c9f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962d6829-aaaa-4ccd-88e9-f178250cb919",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2- Dataset\n",
    "\n",
    "Below we load the data used for this project. Let's start with a description of the data to get the basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f416cfb-d3d5-4c6e-8420-d6baf446168a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Information of the Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5842 entries, 0 to 5841\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Sentence   5842 non-null   object\n",
      " 1   Sentiment  5842 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 91.4+ KB\n",
      "None\n",
      "\n",
      "Sentiment Distribution:\n",
      "Sentiment\n",
      "neutral     3130\n",
      "positive    1852\n",
      "negative     860\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "# Load the data\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Data description and analysis\n",
    "print(\"Basic Information of the Dataset:\")\n",
    "print(df.info())\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab08e6d2-fa9b-4580-a957-8f1712ca12d1",
   "metadata": {},
   "source": [
    "This code below performs data preparation:\n",
    "1. Converts sentiment labels to numerical form using label encoding\n",
    "2. Splits data into training (70%), validation (15%), and testing (15%) sets\n",
    "3. Creates vocabulary from training text with padding and unknown tokens\n",
    "4. Vectorizes text into fixed-length sequences (max length 128)\n",
    "5. Wraps data in custom Dataset classes\n",
    "6. Creates PyTorch DataLoaders for batch processing\n",
    "The resulting DataLoaders provide efficient access to vectorized text and labels for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "208592a3-c864-4b66-b98c-e71727f5250b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data loading completed, Training set size: 4089, Validation set size: 876, Testing set size: 877\n"
     ]
    }
   ],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df['Sentiment'] = label_encoder.fit_transform(df['Sentiment'])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['Sentence'], df['Sentiment'], test_size=0.3, random_state=42)\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Text Tokenization\n",
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "# Build Vocabulary\n",
    "vocab = {}\n",
    "for text in df['Sentence']:\n",
    "    for token in tokenize(text):\n",
    "        if token not in vocab:\n",
    "            vocab[token] = len(vocab)\n",
    "\n",
    "vocab['<pad>'] = len(vocab)  # Padding token\n",
    "vocab['<unk>'] = len(vocab)  # Unknown word token\n",
    "\n",
    "# Text Vectorization\n",
    "def text_to_indices(text, vocab, max_seq_len):\n",
    "    tokens = tokenize(text)\n",
    "    indices = [vocab.get(token, vocab['<unk>']) for token in tokens[:max_seq_len]]\n",
    "    indices += [vocab['<pad>']] * (max_seq_len - len(indices))\n",
    "    return indices\n",
    "\n",
    "max_seq_len = 128  # Maximum sequence length\n",
    "\n",
    "train_df = pd.DataFrame({'Text': train_text, 'Label': train_labels})\n",
    "val_df = pd.DataFrame({'Text': val_text, 'Label': val_labels})\n",
    "test_df = pd.DataFrame({'Text': test_text, 'Label': test_labels})\n",
    "\n",
    "train_df['Text Indices'] = train_df['Text'].apply(lambda x: text_to_indices(x, vocab, max_seq_len))\n",
    "val_df['Text Indices'] = val_df['Text'].apply(lambda x: text_to_indices(x, vocab, max_seq_len))\n",
    "test_df['Text Indices'] = test_df['Text'].apply(lambda x: text_to_indices(x, vocab, max_seq_len))\n",
    "\n",
    "# Create Data Loaders\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.texts[idx]), torch.tensor(self.labels[idx])\n",
    "\n",
    "train_dataset = TextDataset(train_df['Text Indices'].tolist(), train_df['Label'].tolist())\n",
    "val_dataset = TextDataset(val_df['Text Indices'].tolist(), val_df['Label'].tolist())\n",
    "test_dataset = TextDataset(test_df['Text Indices'].tolist(), test_df['Label'].tolist())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"\\nData loading completed, Training set size: {}, Validation set size: {}, Testing set size: {}\".format(len(train_dataset), len(val_dataset), len(test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aadb5ef-d579-48b9-9ecb-236b29301553",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3- Transformer structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc6775-7829-445b-bbcd-8dcc5d13df51",
   "metadata": {},
   "source": [
    "In this section, we will learn how to build the Transformer structure to implement sentiment analysis.The Transformer model architecture follows the standard design from **\"Attention Is All You Need\"**, adapted for text classification tasks with the specified parameters and components. Here are the steps:\n",
    "\n",
    "\n",
    "1. **Implement positional encoding**: Create a function to generate positional encodings that add sequence order information to input embeddings using sine and cosine functions.\n",
    "2. **Implement multi-head attention**: Define a function to perform multi-head attention calculations, including query, key, and value linear transformations, scaled dot-product attention, and output projection.\n",
    "3. **Create feed-forward neural network**: Build a class for the position-wise feed-forward network with two linear layers and a ReLU activation function.\n",
    "4. **Construct encoder layer**: Develop an encoder layer class that combines multi-head self-attention, residual connections, layer normalization, and the feed-forward network.\n",
    "5. **Build encoder**: Create an encoder class that stacks multiple encoder layers.\n",
    "6. **Build Transformer model**: Implement the main Transformer model class that includes:\n",
    "    - An embedding layer for input tokens\n",
    "    - Positional encoding addition\n",
    "    - The encoder stack\n",
    "    - An output layer for classification (3-class sentiment classification in this case)\n",
    "\n",
    "\"Attention Is All You Need\" is an extremely classic paper, there is a high value of learning, you can combine this part of the code with the paper together to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea33f5ec-317f-4a73-b06f-a98c896f8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "def positional_encoding(max_seq_len, d_model):\n",
    "    \"\"\"\n",
    "    Generate positional encodings for transformer models.\n",
    "    \n",
    "    Returns:\n",
    "    torch.Tensor: Positional encodings (1, max_seq_len, d_model)\n",
    "    \"\"\"\n",
    "    # Step 1. Create a tensor to store positional encodings\n",
    "    # Step 2. Generate position indices\n",
    "    # Step 3. Calculate the divisor term for positional encoding\n",
    "    # Step 4. Calculate sine and cosine values for even and odd positions\n",
    "    # Step 5. Add a batch dimension to the positional encodings\n",
    "\n",
    "    ### YOUR CODE BEGINS HERE\n",
    "    positional_encodings = torch.zeros(max_seq_len, d_model)\n",
    "    position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "    \n",
    "    positional_encodings[:, 0::2] = torch.sin(position * div_term)\n",
    "    positional_encodings[:, 1::2] = torch.cos(position * div_term)\n",
    "    \n",
    "    positional_encodings = positional_encodings.unsqueeze(0)\n",
    "    ### YOUR CODE ENDS\n",
    "    \n",
    "    return positional_encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a112c8-bea8-4d58-a04e-c1b768d67184",
   "metadata": {},
   "source": [
    "You may want to run the following code to verify that the above function is written correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c98f50a2-3857-4f88-8292-7dac2f986c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your output:\n",
      " tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
      "          9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
      "        [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
      "          9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
      "        [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
      "          9.9955e-01,  3.0000e-03,  1.0000e+00]])\n",
      "Expected output:\n",
      " tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
      "          9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
      "        [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
      "          9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
      "        [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9996e-02,\n",
      "          9.9955e-01,  3.0000e-03,  1.0000e+00]])\n",
      "Difference:\n",
      " tensor(5.9605e-08)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilig\\AppData\\Local\\Temp\\ipykernel_10376\\4274043822.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  expected_output = torch.tensor(expected_output, dtype=pos_enc.dtype, device=pos_enc.device)\n"
     ]
    }
   ],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "def test_positional_encoding():\n",
    "    max_seq_len = 4\n",
    "    d_model = 8\n",
    "\n",
    "    pos_enc = positional_encoding(max_seq_len, d_model).squeeze(0)\n",
    "\n",
    "    expected_output = torch.zeros(max_seq_len, d_model)\n",
    "    for pos in range(max_seq_len):\n",
    "        for i in range(d_model // 2):\n",
    "            div_term = math.exp(-(math.log(10000.0) / d_model) * (2 * i))\n",
    "            expected_output[pos, 2 * i] = math.sin(pos * div_term)\n",
    "            expected_output[pos, 2 * i + 1] = math.cos(pos * div_term)\n",
    "\n",
    "    expected_output = torch.tensor(expected_output, dtype=pos_enc.dtype, device=pos_enc.device)\n",
    "\n",
    "    print(\"Your output:\\n\", pos_enc)\n",
    "    print(\"Expected output:\\n\", expected_output)\n",
    "    print(\"Difference:\\n\", torch.abs(pos_enc - expected_output).max())\n",
    "\n",
    "test_positional_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e31181-1f4b-4943-a837-2c27de05af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "def multi_head_attention(query, key, value, num_heads, mask=None):\n",
    "    \"\"\"\n",
    "    Perform multi-head attention.\n",
    "    \n",
    "    Returns:\n",
    "    torch.Tensor: Attention output (batch_size, seq_len, d_model)\n",
    "    torch.Tensor: Attention weights (batch_size, num_heads, seq_len, seq_len)\n",
    "    \"\"\"\n",
    "    # Step 1. Get the dimensions (batch size, sequence length, model dimension)\n",
    "    # Step 2. Calculate the dimension for keys and values per head\n",
    "    # Step 3. Create linear transformations for query, key, and value\n",
    "    # Step 4. Apply linear transformations to query, key, and value\n",
    "    # Step 5. Reshape query, key, and value to separate heads\n",
    "    # Step 6. Transpose query, key, and value to (batch_size, num_heads, seq_len, d_k/d_v)\n",
    "    # Step 7. Calculate the attention scores using matrix multiplication\n",
    "    # Step 8. Scale the attention scores\n",
    "    # Step 9. Apply mask if provided\n",
    "    # Step 10. Calculate attention weights using softmax\n",
    "    # Step 11. Calculate attention output using matrix multiplication\n",
    "    # Step 12. Transpose and reshape attention output back to (batch_size, seq_len, d_model)\n",
    "\n",
    "    ### YOUR CODE BEGINS HERE\n",
    "    batch_size = query.shape[0]\n",
    "    seq_len = query.shape[1]\n",
    "    d_model = query.shape[2]\n",
    "    d_k = d_model // num_heads\n",
    "    d_v = d_model // num_heads\n",
    "\n",
    "    # Create linear transformations for query, key, and value\n",
    "    query_linear = nn.Linear(d_model, d_model).to(query.device)\n",
    "    key_linear = nn.Linear(d_model, d_model).to(query.device)\n",
    "    value_linear = nn.Linear(d_model, d_model).to(query.device)\n",
    "\n",
    "    # Apply linear transformations\n",
    "    query = query_linear(query)\n",
    "    key = key_linear(key)\n",
    "    value = value_linear(value)\n",
    "\n",
    "    # Reshape and transpose query, key, and value\n",
    "    query = query.reshape(batch_size, -1, num_heads, d_k).transpose(1, 2)\n",
    "    key = key.reshape(batch_size, -1, num_heads, d_k).transpose(1, 2)\n",
    "    value = value.reshape(batch_size, -1, num_heads, d_v).transpose(1, 2)\n",
    "\n",
    "    # Calculate attention scores\n",
    "    matmul_qk = torch.matmul(query, key.transpose(-2, -1))\n",
    "    dk = query.shape[-1]\n",
    "    scaled_attention_scores = matmul_qk / math.sqrt(dk)\n",
    "\n",
    "    # Apply mask if provided\n",
    "    if mask is not None:\n",
    "        scaled_attention_scores = scaled_attention_scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "    # Calculate attention weights\n",
    "    attention_weights = torch.softmax(scaled_attention_scores, dim=-1)\n",
    "\n",
    "    # Calculate attention output\n",
    "    attention_output = torch.matmul(attention_weights, value)\n",
    "\n",
    "    # Transpose and reshape attention output\n",
    "    attention_output = attention_output.transpose(1, 2).reshape(batch_size, seq_len, d_model)\n",
    "    ### YOUR CODE ENDS\n",
    "    \n",
    "    return attention_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c659a63-161b-40cc-8ba8-6a698d47da66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        \"\"\"\n",
    "        Feed-Forward Network (FFN) used in transformer architecture.\n",
    "        \n",
    "        \"\"\"\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        # Step 1. Create the first fully connected layer (d_model -> d_ff)\n",
    "        # Step 2. Create the ReLU activation function\n",
    "        # Step 3. Create the second fully connected layer (d_ff -> d_model)\n",
    "\n",
    "        ### YOUR CODE BEGINS HERE\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        ### YOUR CODE ENDS\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the feed-forward network.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Output tensor (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        # Step 1. Pass input through the first fully connected layer\n",
    "        # Step 2. Apply ReLU activation\n",
    "        # Step 3. Pass through the second fully connected layer\n",
    "\n",
    "        ### YOUR CODE BEGINS HERE\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        ### YOUR CODE ENDS\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f71819ef-3a66-4baf-ae44-9fc7b8ffea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, num_heads, d_model, d_ff, dropout_rate=0.1):\n",
    "        \"\"\"\n",
    "        Encoder layer of the transformer architecture.\n",
    "        \"\"\"\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        # Step 1. Initialize multi-head self-attention layer\n",
    "        # Step 2. Initialize feed-forward network\n",
    "        # Step 3. Initialize layer normalization layers\n",
    "        # Step 4. Initialize dropout layers\n",
    "\n",
    "        ### YOUR CODE BEGINS HERE\n",
    "        self.self_attention = multi_head_attention\n",
    "        self.feed_forward = FeedForwardNetwork(d_model, d_ff)\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.num_heads = num_heads\n",
    "        ### YOUR CODE ENDS\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the encoder layer.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Output tensor (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        # Step 1. Perform multi-head self-attention\n",
    "        # Step 2. Apply dropout to attention output\n",
    "        # Step 3. Add residual connection and layer normalization\n",
    "        # Step 4. Pass through feed-forward network\n",
    "        # Step 5. Apply dropout to feed-forward output\n",
    "        # Step 6. Add residual connection and layer normalization\n",
    "\n",
    "        ### YOUR CODE BEGINS HERE\n",
    "        attention_output, _ = self.self_attention(x, x, x, self.num_heads, mask)\n",
    "        attention_output = self.dropout1(attention_output)\n",
    "        x = self.layer_norm1(x + attention_output)\n",
    "        \n",
    "        ff_output = self.feed_forward(x)\n",
    "        ff_output = self.dropout2(ff_output)\n",
    "        x = self.layer_norm2(x + ff_output)\n",
    "        ### YOUR CODE ENDS\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfc65a0d-1bcc-4135-925e-83efa546d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_layers, num_heads, d_model, d_ff, dropout_rate=0.1):\n",
    "        \"\"\"\n",
    "        Encoder of the transformer architecture.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        # Step 1. Create a list of encoder layers using ModuleList\n",
    "        # Step 2. Each encoder layer should be initialized with the given parameters\n",
    "\n",
    "        ### YOUR CODE BEGINS HERE\n",
    "        self.layers = nn.ModuleList([EncoderLayer(num_heads, d_model, d_ff, dropout_rate) for _ in range(num_layers)])\n",
    "        ### YOUR CODE ENDS\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the encoder.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Output tensor (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        # Step 1. Pass input through each encoder layer in sequence\n",
    "        # Step 2. Apply each layer to the output of the previous layer\n",
    "\n",
    "        ### YOUR CODE BEGINS HERE\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        ### YOUR CODE ENDS\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f59738a-3100-4472-8482-52e64cfae793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_len, num_layers=6, num_heads=8, d_model=512, d_ff=2048, dropout_rate=0.1):\n",
    "        \"\"\"\n",
    "        Transformer model for text classification.\n",
    "        \"\"\"\n",
    "        super(TransformerModel, self).__init__()\n",
    "        # Step 1. Initialize the token embedding layer\n",
    "        # Step 2. Initialize the positional encoding\n",
    "        # Step 3. Initialize the encoder\n",
    "        # Step 4. Initialize the output layer\n",
    "\n",
    "        ### YOUR CODE BEGINS HERE\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = positional_encoding(max_seq_len, d_model)\n",
    "        self.encoder = Encoder(num_layers, num_heads, d_model, d_ff, dropout_rate)\n",
    "        self.output_layer = nn.Linear(d_model, 3)  # 3-class sentiment classification\n",
    "        ### YOUR CODE ENDS\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the transformer model.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Output tensor (batch_size, 3)\n",
    "        \"\"\"\n",
    "        # Step 1. Convert input tokens to embeddings\n",
    "        # Step 2. Add positional encodings to embeddings\n",
    "        # Step 3. Pass through the encoder\n",
    "        # Step 4. Extract the CLS token output\n",
    "        # Step 5. Pass through the output layer\n",
    "\n",
    "        ### YOUR CODE BEGINS HERE\n",
    "        x = self.embedding(x)\n",
    "        x += self.positional_encoding[:, :x.shape[1], :].to(x.device)\n",
    "        x = self.encoder(x, mask)\n",
    "        cls_output = x[:, 0, :]\n",
    "        output = self.output_layer(cls_output)\n",
    "        ### YOUR CODE ENDS\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c234ef-a752-4e3f-9bf7-4c8912443ca0",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4- Training and Saving Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce71483-dda1-4094-933c-4f63568f3d86",
   "metadata": {},
   "source": [
    "Next we train the Transformer model on a text classification task, including steps such as device management, data loading, model definition, training loop and model persistence. Please run the following code on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfdd2e62-848a-45a4-856e-549c084f079d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Train Loss: 1.0470, Train Acc: 0.4967\n",
      "Val Loss: 1.0391, Val Acc: 0.5240\n",
      "\n",
      "Epoch 2/3\n",
      "Train Loss: 1.0038, Train Acc: 0.5182\n",
      "Val Loss: 1.0263, Val Acc: 0.4863\n",
      "\n",
      "Epoch 3/3\n",
      "Train Loss: 0.9755, Train Acc: 0.5268\n",
      "Val Loss: 1.0175, Val Acc: 0.5297\n",
      "\n",
      "Test Loss: 0.9906, Test Acc: 0.5165\n",
      "Model has been saved\n",
      "\n",
      "Your result should be:\n",
      " Epoch 1/3\n",
      "Train Loss: 1.0470, Train Acc: 0.4967\n",
      "Val Loss: 1.0391, Val Acc: 0.5240\n",
      "\n",
      "Epoch 2/3\n",
      "Train Loss: 1.0038, Train Acc: 0.5182\n",
      "Val Loss: 1.0263, Val Acc: 0.4863\n",
      "\n",
      "Epoch 3/3\n",
      "Train Loss: 0.9755, Train Acc: 0.5268\n",
      "Val Loss: 1.0175, Val Acc: 0.5297\n",
      "Test Loss: 0.9906, Test Acc: 0.5165\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "# PLEASE DO NOT CHANGE THE FOLLOWING CODE\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define hyperparameters\n",
    "vocab_size = len(vocab)\n",
    "max_seq_len = 128\n",
    "num_layers = 6\n",
    "num_heads = 8\n",
    "d_model = 512\n",
    "d_ff = 2048\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# Initialize model\n",
    "model = TransformerModel(vocab_size, max_seq_len, num_layers, num_heads, d_model, d_ff, dropout_rate)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Ensure data is on the correct device\n",
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(dataloader), accuracy\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs, labels = batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(dataloader), accuracy\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\\n')\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'transformer_model.pth')\n",
    "print(\"Model has been saved\")\n",
    "\n",
    "\n",
    "print(\"\\nYour result should be:\\n Epoch 1/3\\nTrain Loss: 1.0470, Train Acc: 0.4967\\nVal Loss: 1.0391, Val Acc: 0.5240\\n\\nEpoch 2/3\\nTrain Loss: 1.0038, Train Acc: 0.5182\\nVal Loss: 1.0263, Val Acc: 0.4863\\n\\nEpoch 3/3\\nTrain Loss: 0.9755, Train Acc: 0.5268\\nVal Loss: 1.0175, Val Acc: 0.5297\\nTest Loss: 0.9906, Test Acc: 0.5165\\nModel has been saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad7f55-8e61-4f57-adae-76d814ab2535",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5- Play by Yourself!\n",
    "\n",
    "For this assignment we completed a text classification task using Transformer. There are other RNNs that we have learnt in this course and you can try your hand at writing code to complete the project yourself.The online materials for this course can be a good reference for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c267a3-653c-4278-990a-5460e416201e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
